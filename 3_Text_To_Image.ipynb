{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f63d8e06-8027-42f4-9824-826a534f6407",
   "metadata": {},
   "source": [
    "Let's move on to simulating a Text-to-Image model using Hugging Face in your JupyterHub environment. We won't be able to run the full training or inference of a state-of-the-art Text-to-Image model like Stable Diffusion within a standard JupyterHub environment due to the significant computational resources (especially GPU) required.\n",
    "\n",
    "However, Lets demonstrate the basic steps of:\n",
    "\n",
    "1. Installing necessary libraries.\n",
    "2. Loading a pre-trained Text-to-Image pipeline from Hugging Face's diffusers library.\n",
    "3. Running a very basic inference to show how it works (this might be slow on CPU and might produce a less impressive image without significant compute).\n",
    "4. Displaying the generated image (if possible within your JupyterHub setup).\n",
    "\n",
    "Here's the Python script you can execute in your JupyterHub notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d99785-bc8c-4a15-b05c-678167a28656",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install diffusers transformers accelerate scipy Pillow --trusted-host pypi.org --trusted-host files.pythonhosted.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d844fc6-9fb7-4d08-9532-33823b3f6f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a9e539e-43a7-46ec-b57d-d454fca9fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the pre-trained Stable Diffusion model from Hugging Face\n",
    "# You can try other models as well, but 'runwayml/stable-diffusion-v1-5' is a good starting point\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d487f212-045a-41b3-ad1b-a59911782425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7daa03653444168b1a5b9c2d270715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3aca2d9f1140a4ade39821b3452c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as generated_image.png\n"
     ]
    }
   ],
   "source": [
    "# Load the Stable Diffusion pipeline\n",
    "# This will download the model weights and configurations from Hugging Face\n",
    "try:\n",
    "    pipeline = StableDiffusionPipeline.from_pretrained(model_id)\n",
    "\n",
    "    # If you have a CUDA-enabled GPU available in your JupyterHub environment,\n",
    "    # uncomment the following line to move the pipeline to the GPU for faster inference.\n",
    "    # pipeline = pipeline.to(\"cuda\")\n",
    "\n",
    "    # The text prompt you want to generate an image from\n",
    "    prompt = \"A futuristic cityscape at sunset, with flying cars.\"\n",
    "\n",
    "    # Generate the image\n",
    "    # 'num_inference_steps' controls the number of denoising steps (higher = better quality, slower)\n",
    "    # 'guidance_scale' controls how much the image generation follows the prompt (higher = more adherence)\n",
    "    image = pipeline(prompt, num_inference_steps=30, guidance_scale=7.5).images[0]\n",
    "\n",
    "    # Display the generated image\n",
    "    image.save(\"generated_image.png\")  # Save the image\n",
    "    print(\"Image saved as generated_image.png\")\n",
    "\n",
    "    # If you are in an environment where you can directly display images (e.g., not just a terminal),\n",
    "    # you might be able to display it within the notebook:\n",
    "    # image.show() # This might not work in all JupyterHub setups\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"It's possible that the model download or inference failed due to resource constraints (CPU/RAM).\")\n",
    "    print(\"Text-to-Image models are very demanding on computational resources, especially GPU.\")\n",
    "    print(\"If you don't have a GPU, inference will be very slow and might lead to errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba93a12-86e6-4bbc-bb5b-4f4fc1eff01d",
   "metadata": {},
   "source": [
    "# Explanation of the Script: #\n",
    "\n",
    "`!pip install diffusers transformers accelerate scipy Pillow`\n",
    "\n",
    "This line installs the necessary libraries:\n",
    "1. `diffusers`: Hugging Face's library specifically for diffusion models like Stable Diffusion.\n",
    "2. `transformers`: The core Hugging Face library for various NLP and multimodal models.\n",
    "3. `accelerate`: A library that helps run PyTorch code on different hardware setups (CPU, GPU, TPUs).\n",
    "4. `scipy`: A library for scientific computing (used internally by some models).\n",
    "5. `Pillow (PIL)`: A library for image manipulation.\n",
    "\n",
    "`from diffusers import StableDiffusionPipeline` : Imports the StableDiffusionPipeline, which is a high-level abstraction for running the Stable Diffusion model for text-to-image generation.\n",
    "\n",
    "`from PIL import Image`: Imports the Image class from Pillow for handling image objects.\n",
    "\n",
    "`model_id = \"runwayml/stable-diffusion-v1-5\"`: Specifies the identifier of the pre-trained Stable Diffusion model on the Hugging Face Model Hub. \"runwayml/stable-diffusion-v1-5\" is a widely used and relatively accessible version.\n",
    "\n",
    "`pipeline = StableDiffusionPipeline.from_pretrained(model_id)`: This is the crucial step. It downloads the model weights and configuration files for the specified model_id from Hugging Face and loads them into the StableDiffusionPipeline. This might take a significant amount of time and disk space (several gigabytes).\n",
    "\n",
    "`pipeline = pipeline.to(\"cuda\")`: This line is commented out. If your JupyterHub environment has access to a CUDA-enabled NVIDIA GPU, uncomment this line to move the entire pipeline to the GPU. This will drastically speed up the image generation process. Without a GPU, the inference will run on the CPU, which will be very slow and might even lead to memory issues or timeouts.\n",
    "\n",
    "`prompt = \"A futuristic cityscape at sunset, with flying cars.\"`: This is the text prompt that you want the model to generate an image based on. Feel free to change this to any description you like.\n",
    "\n",
    "`image = pipeline(prompt, num_inference_steps=30, guidance_scale=7.5).images[0]`: This line performs the image generation:\n",
    "\n",
    "`prompt`: The input text.\n",
    "\n",
    "`num_inference_steps`: The number of denoising steps the diffusion process will take. Higher values generally lead to better quality but take longer.\n",
    "\n",
    "`guidance_scale`: A parameter that controls how closely the generated image follows the prompt. Higher values encourage more adherence to the prompt but can sometimes reduce image quality.\n",
    "\n",
    "`.images[0]`: The pipeline returns a list of generated images. We take the first one.\n",
    "image.save(\"generated_image.png\"): This saves the generated PIL.Image object to a file named generated_image.png in your JupyterHub's working directory. You should be able to download this file.\n",
    "\n",
    "`print(\"Image saved as generated_image.png\")`: A confirmation message.\n",
    "\n",
    "`image.show()`: This line is commented out because the image.show() method often requires a graphical interface and might not work directly within a JupyterHub environment that is accessed through a web browser. Saving the image is a more reliable way to see the output.\n",
    "\n",
    "`try...except block`: This is included to catch potential errors, especially related to resource constraints or the inability to download the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf9cd84-ab97-48e7-a8dd-50e5f39185cb",
   "metadata": {},
   "source": [
    "# Important Considerations for JupyterHub: #\n",
    "\n",
    "`Resource Limits`: Text-to-Image models, especially Stable Diffusion, are very resource-intensive. Your JupyterHub environment might have limitations on CPU, RAM, and the availability of GPUs. Running this script, especially without a GPU, might be extremely slow or even fail due to memory errors.\n",
    "\n",
    "`GPU Availability`: Check if your JupyterHub instance is configured to provide access to GPUs. If it is, make sure you uncomment the pipeline.to(\"cuda\") line.\n",
    "\n",
    "`Disk Space`: Downloading the pre-trained model will require several gigabytes of disk space in your JupyterHub user directory.\n",
    "\n",
    "`Inference Time`: Even with a decent GPU, generating a single image can take several seconds to minutes, depending on the number of inference steps and other parameters. On a CPU, it could take much longer.\n",
    "\n",
    "`Displaying Images`: Directly displaying images within a JupyterHub notebook can sometimes have limitations depending on the setup. Saving the image to a file (.png, .jpg) is the most reliable way to view the result.\n",
    "\n",
    "This script provides a basic simulation of using a Text-to-Image model from Hugging Face. Keep in mind the resource limitations of your JupyterHub environment. If you have access to more powerful computing resources (like a dedicated GPU machine or a cloud-based GPU instance), you'll be able to run this much more effectively and explore more complex prompts and model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6153f6a5-ce9c-493e-8e67-2e931a1676ab",
   "metadata": {},
   "source": [
    "# Troubleshooting #\n",
    "\n",
    "`--trusted-host` parameter specified to overcome the SSL Certificate issues.\n",
    "\n",
    "An error occurred: Torch not compiled with CUDA enabled\n",
    "It's possible that the model download or inference failed due to resource constraints (CPU/RAM).\n",
    "Text-to-Image models are very demanding on computational resources, especially GPU.\n",
    "If you don't have a GPU, inference will be very slow and might lead to errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450ca9da-f3dc-4df1-8cd0-b352a112bb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
