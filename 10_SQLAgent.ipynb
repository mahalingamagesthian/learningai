{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqZ4m5tWmufaQQFOdgjllg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahalingamagesthian/learningai/blob/main/10_SQLAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This page is inspired from https://langchain-ai.github.io/langgraph/tutorials/sql-agent/"
      ],
      "metadata": {
        "id": "NH8LtYOJruwk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bcQJf-BDrIWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "a48d91f5-af24-4eca-8b8d-7315aea58f18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.5.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain[openai] in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.67)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.6.0,>=0.5.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.72-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.4)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain[openai]) (0.3.8)\n",
            "Collecting langchain-openai (from langchain[openai])\n",
            "  Downloading langchain_openai-0.3.27-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai->langchain[openai]) (1.93.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai->langchain[openai]) (0.9.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai->langchain[openai]) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai->langchain[openai]) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai->langchain[openai]) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai->langchain[openai]) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai->langchain[openai]) (2024.11.6)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langgraph-0.5.1-py3-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.7/143.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.5.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.72-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.27-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, ormsgpack, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, langgraph-sdk, dataclasses-json, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-openai-0.3.27 langchain_community-0.3.27 langgraph-0.5.1 langgraph-checkpoint-2.1.0 langgraph-prebuilt-0.5.2 langgraph-sdk-0.1.72 marshmallow-3.26.1 mypy-extensions-1.1.0 ormsgpack-1.10.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install -U langgraph langchain_community \"langchain[openai]\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In SQL Agent project, this llm instance will be responsible for:\n",
        "\n",
        " * Translating your natural language questions into executable SQL queries.\n",
        " * Reasoning about the results returned from the database.\n",
        " * Deciding which tools to call (e.g., \"query the database,\" \"get table schema\").\n",
        " * Synthesizing the final answer for the user based on the query results.\n",
        "\n",
        "This is the central intelligence component of your agent.\n",
        "\n",
        "1. `from langchain.chat_models import init_chat_model:`\n",
        "\n",
        "   * `init_chat_model:` This is a convenient helper function from the langchain.chat_models module.\n",
        "   * `Purpose`: Its purpose is to make it easy to initialize a chat model from various providers (like OpenAI, Anthropic, Google, etc.) with a simple string identifier. Instead of needing to know and import a specific class like ChatOpenAI, you can just use this function with a provider-specific string. This makes your code more portable and easier to read.\n",
        "2. `llm = init_chat_model(\"openai:gpt-4.1\"):`\n",
        "\n",
        "   * `llm:` This is a standard variable name in LangChain for the initialized Language Model instance. You will use this variable to interact with the model throughout your code.\n",
        "   * `\"openai:gpt-4.1\":` This is the key argument. It's a string that tells the init_chat_model function exactly which model to initialize.\n",
        "      * `openai:` This is the provider. It specifies that you want to use a model from OpenAI.\n",
        "      * `gpt-4.1:` This is the model name. It refers to a powerful and highly capable version of OpenAI's GPT-4 model, which is excellent for complex reasoning tasks like building a SQL agent."
      ],
      "metadata": {
        "id": "Yy1B6YQEE60p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "def _set_env(key: str):\n",
        "    if key not in os.environ:\n",
        "        os.environ[key] = getpass.getpass(f\"{key}:\")\n",
        "\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFYrXzbhJAn-",
        "outputId": "159501b3-8e21-4b5e-93a0-2903c98bcf1f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "llm = init_chat_model(\"openai:gpt-4.1\")"
      ],
      "metadata": {
        "id": "P46qgLqqruMn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script's purpose is to provide the **SQLite database file** (Chinook.db) that your SQL agent will connect to. After you run this code, the file will be stored locally, and your agent will be able to access its schema and execute queries against it in the next steps. It's a critical setup step that lays the groundwork for the agent's interaction with the data."
      ],
      "metadata": {
        "id": "NC1mKT26HsgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import the necessary library\n",
        "import requests\n",
        "# 2. Define the URL of the database file\n",
        "url = \"https://storage.googleapis.com/benchmarks-artifacts/chinook/Chinook.db\"\n",
        "# 3. Send an HTTP GET request to download the file\n",
        "response = requests.get(url)\n",
        "# 4. Check if the download was successful\n",
        "if response.status_code == 200:\n",
        "    # 5. If successful, save the downloaded content to a local file\n",
        "    # Open a local file in binary write mode ('wb')\n",
        "    with open(\"Chinook.db\", \"wb\") as file:\n",
        "        # Write the content of the response (the file) to the local file\n",
        "        file.write(response.content)\n",
        "    print(\"File downloaded and saved as Chinook.db\")\n",
        "else:\n",
        "    # 6. If not successful, print an error message\n",
        "    print(f\"Failed to download the file. Status code: {response.status_code}\")"
      ],
      "metadata": {
        "id": "SUxZkRAWsACK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "437c2d35-bf81-40c0-f4eb-86e303ce2e71"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and saved as Chinook.db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import the utility class for interacting with SQL databases\n",
        "from langchain_community.utilities import SQLDatabase\n",
        "# 2. Create a SQLDatabase instance from the local database file\n",
        "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
        "# 3. Print the database dialect (type) to verify the connection\n",
        "print(f\"Dialect: {db.dialect}\")\n",
        "# 4. Get and print the names of all usable tables\n",
        "print(f\"Available tables: {db.get_usable_table_names()}\")\n",
        "# 5. Execute a raw SQL query and print a sample of the results\n",
        "print(f'Sample output: {db.run(\"SELECT * FROM Artist LIMIT 5;\")}')"
      ],
      "metadata": {
        "id": "fPYDSlS-sGTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26ff2412-66a3-4ff0-88e1-b9bdf664e632"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialect: sqlite\n",
            "Available tables: ['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n",
            "Sample output: [(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step is a crucial bridge between your LLM and your database.\n",
        "\n",
        "  * You've given the agent its brain (llm).\n",
        "  * You've given it a database to work with (db).\n",
        "  * This code gives the agent the hands (the tools) it needs to actually interact with that database.\n",
        "\n",
        "1. `from langchain_community.agent_toolkits import SQLDatabaseToolkit:`\n",
        "\n",
        "  * This line imports the SQLDatabaseToolkit class.\n",
        "  * In **LangChain**, a Toolkit is a collection of related, pre-built Tool objects designed for a specific domain or purpose. This saves you from having to write each tool from scratch. This toolkit contains all the essential functions for interacting with a SQL database.\n",
        "\n",
        "2. `toolkit = SQLDatabaseToolkit(db=db, llm=llm):`\n",
        "\n",
        "  * This line creates an instance of the `SQLDatabaseToolkit`.\n",
        "  * `db=db`: You are passing the SQLDatabase connection object (db) you created in the previous step. This is how the toolkit knows which database to connect to when its tools are called.\n",
        "  * `llm=llm`: You are also passing your initialized LLM (llm). The toolkit uses the LLM for internal logic, such as getting the database schema, as it might need to reason about which tables to include in the context for the agent.\n",
        "3. `tools = toolkit.get_tools():`\n",
        "\n",
        "  * This line calls the `get_tools()` method on the toolkit instance.\n",
        "  * This method's purpose is to generate and return a list of `Tool` objects that are part of the toolkit.\n",
        "  * Each `Tool` object has a `name` and a `description` that the LLM can read and understand.\n",
        "4. `for tool in tools: print(...):`\n",
        "\n",
        "  * This is a simple for loop that iterates through the list of tools you just retrieved.\n",
        "  * For each tool, it prints its `name` and `description`.\n",
        "\n",
        "When you run this code, you will see a list of tools with descriptions similar to the following (the exact descriptions might vary slightly with library updates):\n",
        "\n",
        " * `sql_db_query`: A tool for executing a SQL query. The LLM will use this for the actual query execution.\n",
        " * `sql_db_schema`: A tool for getting the schema (table names and column names) of specific tables. The LLM will use this to understand the structure of the tables before writing a query.\n",
        " * `sql_db_list_tables`: A tool for listing all the tables in the database.\n",
        " * `sql_db_query_checker`: A helper tool that checks the validity of a SQL query before execution.\n"
      ],
      "metadata": {
        "id": "BWAN9bjfig5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import the SQLDatabaseToolkit class\n",
        "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
        "# 2. Initialize the toolkit with your database connection and LLM\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "\n",
        "# 3. Get the list of pre-built tools from the toolkit\n",
        "tools = toolkit.get_tools()\n",
        "# 4. Iterate through the tools and print their names and descriptions\n",
        "for tool in tools:\n",
        "    print(f\"{tool.name}: {tool.description}\\n\")"
      ],
      "metadata": {
        "id": "fy0UBQp1sXdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97d2f9c1-180e-4a0a-da1f-b4483f9884c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sql_db_query: Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\n",
            "\n",
            "sql_db_schema: Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3\n",
            "\n",
            "sql_db_list_tables: Input is an empty string, output is a comma-separated list of tables in the database.\n",
            "\n",
            "sql_db_query_checker: Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In the Context of Your SQL Agent Project:**\n",
        "\n",
        "This code creates a single, `self-contained AI agent` that can now take a natural language question (e.g., \"How many employees are in the Employee table?\") and, using its internal reasoning loop and tools, figure out the necessary steps to answer it:\n",
        "\n",
        " * `Thought:` \"The user wants to know the employee count. I should check the available tables first.\"\n",
        " * `Action:` Calls the `sql_db_list_tables` tool.\n",
        " * `Observation`: \"The tables are Artist, Album, Employee, etc.\"\n",
        " * `Thought:` \"Okay, I see an Employee table. Now I need to write a SQL query to count the rows.\"\n",
        " * `Action:` Calls the sql_db_query tool with SELECT COUNT(*) FROM Employee;.\n",
        " * `Observation`: \"The query result is (8,).\"\n",
        " * `Thought:` \"I have the count. I can now provide the final answer.\"\n",
        " * `Final Answer:` \"There are 8 employees in the database.\"\n",
        "\n",
        "1. `from langgraph.prebuilt import create_react_agent:`\n",
        "\n",
        "   * This line imports a pre-built function from the LangGraph library.\n",
        "   * `create_react_agent`: This is a powerful helper function that simplifies the creation of a ReAct agent.\n",
        "   * `ReAct (Reasoning and Acting):` This is a well-known agent pattern where the LLM follows an iterative cycle:\n",
        "     * `Thought:` The LLM thinks about the user's request and decides on a plan.\n",
        "     * `Action:` It calls one of its available tools (e.g., sql_db_query).\n",
        "     * `Observation:` It receives the output from the tool (e.g., the result of the query).\n",
        "     * `Thought...:` It then uses this observation to decide on the next step, repeating the cycle until it has a final answer.\n",
        "  * langgraph.prebuilt provides this pattern out of the box, saving you from having to build the entire graph logic yourself.\n",
        "2. `system_prompt = \"\"\"...\"\"\".format(...):`\n",
        "\n",
        "  * This code block defines the system prompt. This is a crucial instruction set that gives the LLM its identity, role, and rules of engagement.\n",
        "  * `\"\"\"...\"\"\"`: This is a multi-line string that contains the detailed instructions for the agent.\n",
        "  * `Role:` \"You are an agent designed to interact with a SQL database.\" This immediately sets the context for the LLM.\n",
        "  * `Instructions:` The prompt contains explicit rules and best practices for the agent's behavior:\n",
        "    * `Query generation:` \"create a syntactically correct... query.\"\n",
        "    * `Result handling:` \"look at the results... and return the answer.\"\n",
        "    * **safeguards**\n",
        "      * `LIMIT clause:` \"always limit your query to at most {top_k} results.\"\n",
        "      * This prevents the agent from fetching huge amounts of data and potentially running up costs or causing performance issues.\n",
        "      * `Relevant columns:` \"Never query for all the columns.\" This promotes efficiency.\n",
        "      * `Double-checking queries:` \"MUST double check your query before executing it.\" This is a key part of the agent's self-correction loop.\n",
        "      * `DML statements:` \"DO NOT make any DML statements.\" This is a critical security instruction to prevent the agent from modifying, deleting, or dropping data in the database.\n",
        "      * `Initial steps:` \"ALWAYS look at the tables...\" This forces the agent to start by exploring the schema, which is a robust strategy for tackling a new database.\n",
        "  * `.format(dialect=db.dialect, top_k=5,):` This uses Python's `str.format()` method to dynamically insert values into the prompt.\n",
        "  * `{dialect}:` This placeholder will be replaced with 'sqlite', making the prompt specific to your database.\n",
        "  * `{top_k}:` This placeholder is replaced with 5, setting the default query limit.\n",
        "\n",
        "3. `agent = create_react_agent(...):`\n",
        "  * This is where you assemble the agent.\n",
        "  * `agent:` This variable now holds the compiled, ready-to-use ReAct agent. It's a runnable object.\n",
        "  * `llm:` You are providing the LLM instance you initialized earlier (openai:gpt-4.1). This is the reasoning engine.\n",
        "  * `tools:` You are providing the list of SQL tools you retrieved from the toolkit. These are the actions the agent can take.\n",
        "  * `prompt=system_prompt:` You are giving the agent its identity and instructions through the system prompt you defined.\n",
        "\n"
      ],
      "metadata": {
        "id": "8tno1Tszp3Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import the prebuilt ReAct agent constructor from LangGraph\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "# 2. Define the system prompt that gives the agent its identity and rules\n",
        "system_prompt = \"\"\"\n",
        "You are an agent designed to interact with a SQL database.\n",
        "Given an input question, create a syntactically correct {dialect} query to run,\n",
        "then look at the results of the query and return the answer. Unless the user\n",
        "specifies a specific number of examples they wish to obtain, always limit your\n",
        "query to at most {top_k} results.\n",
        "\n",
        "You can order the results by a relevant column to return the most interesting\n",
        "examples in the database. Never query for all the columns from a specific table,\n",
        "only ask for the relevant columns given the question.\n",
        "\n",
        "You MUST double check your query before executing it. If you get an error while\n",
        "executing a query, rewrite the query and try again.\n",
        "\n",
        "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the\n",
        "database.\n",
        "\n",
        "To start you should ALWAYS look at the tables in the database to see what you\n",
        "can query. Do NOT skip this step.\n",
        "\n",
        "Then you should query the schema of the most relevant tables.\n",
        "\"\"\".format(\n",
        "    dialect=db.dialect,\n",
        "    top_k=5,\n",
        ")\n",
        "\n",
        "# 3. Create the agent instance\n",
        "agent = create_react_agent(\n",
        "    llm,\n",
        "    tools,\n",
        "    prompt=system_prompt,\n",
        ")"
      ],
      "metadata": {
        "id": "cmxzZsUisfgX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Which sales agent made the most in sales in 2009?\"\n",
        "\n",
        "for step in agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "jr4AlyLrsiTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09b7f0cf-2de0-4d91-e18b-d2ee16e70923"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Which sales agent made the most in sales in 2009?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_list_tables (call_njlaLJkKEAnuF9RMvIkgKAEk)\n",
            " Call ID: call_njlaLJkKEAnuF9RMvIkgKAEk\n",
            "  Args:\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_list_tables\n",
            "\n",
            "Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_schema (call_e5Ez10h0U990WlGn8PbWyOIy)\n",
            " Call ID: call_e5Ez10h0U990WlGn8PbWyOIy\n",
            "  Args:\n",
            "    table_names: Employee, Invoice\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_schema\n",
            "\n",
            "\n",
            "CREATE TABLE \"Employee\" (\n",
            "\t\"EmployeeId\" INTEGER NOT NULL, \n",
            "\t\"LastName\" NVARCHAR(20) NOT NULL, \n",
            "\t\"FirstName\" NVARCHAR(20) NOT NULL, \n",
            "\t\"Title\" NVARCHAR(30), \n",
            "\t\"ReportsTo\" INTEGER, \n",
            "\t\"BirthDate\" DATETIME, \n",
            "\t\"HireDate\" DATETIME, \n",
            "\t\"Address\" NVARCHAR(70), \n",
            "\t\"City\" NVARCHAR(40), \n",
            "\t\"State\" NVARCHAR(40), \n",
            "\t\"Country\" NVARCHAR(40), \n",
            "\t\"PostalCode\" NVARCHAR(10), \n",
            "\t\"Phone\" NVARCHAR(24), \n",
            "\t\"Fax\" NVARCHAR(24), \n",
            "\t\"Email\" NVARCHAR(60), \n",
            "\tPRIMARY KEY (\"EmployeeId\"), \n",
            "\tFOREIGN KEY(\"ReportsTo\") REFERENCES \"Employee\" (\"EmployeeId\")\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from Employee table:\n",
            "EmployeeId\tLastName\tFirstName\tTitle\tReportsTo\tBirthDate\tHireDate\tAddress\tCity\tState\tCountry\tPostalCode\tPhone\tFax\tEmail\n",
            "1\tAdams\tAndrew\tGeneral Manager\tNone\t1962-02-18 00:00:00\t2002-08-14 00:00:00\t11120 Jasper Ave NW\tEdmonton\tAB\tCanada\tT5K 2N1\t+1 (780) 428-9482\t+1 (780) 428-3457\tandrew@chinookcorp.com\n",
            "2\tEdwards\tNancy\tSales Manager\t1\t1958-12-08 00:00:00\t2002-05-01 00:00:00\t825 8 Ave SW\tCalgary\tAB\tCanada\tT2P 2T3\t+1 (403) 262-3443\t+1 (403) 262-3322\tnancy@chinookcorp.com\n",
            "3\tPeacock\tJane\tSales Support Agent\t2\t1973-08-29 00:00:00\t2002-04-01 00:00:00\t1111 6 Ave SW\tCalgary\tAB\tCanada\tT2P 5M5\t+1 (403) 262-3443\t+1 (403) 262-6712\tjane@chinookcorp.com\n",
            "*/\n",
            "\n",
            "\n",
            "CREATE TABLE \"Invoice\" (\n",
            "\t\"InvoiceId\" INTEGER NOT NULL, \n",
            "\t\"CustomerId\" INTEGER NOT NULL, \n",
            "\t\"InvoiceDate\" DATETIME NOT NULL, \n",
            "\t\"BillingAddress\" NVARCHAR(70), \n",
            "\t\"BillingCity\" NVARCHAR(40), \n",
            "\t\"BillingState\" NVARCHAR(40), \n",
            "\t\"BillingCountry\" NVARCHAR(40), \n",
            "\t\"BillingPostalCode\" NVARCHAR(10), \n",
            "\t\"Total\" NUMERIC(10, 2) NOT NULL, \n",
            "\tPRIMARY KEY (\"InvoiceId\"), \n",
            "\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from Invoice table:\n",
            "InvoiceId\tCustomerId\tInvoiceDate\tBillingAddress\tBillingCity\tBillingState\tBillingCountry\tBillingPostalCode\tTotal\n",
            "1\t2\t2009-01-01 00:00:00\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t1.98\n",
            "2\t4\t2009-01-02 00:00:00\tUllevålsveien 14\tOslo\tNone\tNorway\t0171\t3.96\n",
            "3\t8\t2009-01-03 00:00:00\tGrétrystraat 63\tBrussels\tNone\tBelgium\t1000\t5.94\n",
            "*/\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_schema (call_PoY1jTQRQb5ElVG1mh8ZRZjp)\n",
            " Call ID: call_PoY1jTQRQb5ElVG1mh8ZRZjp\n",
            "  Args:\n",
            "    table_names: Customer\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_schema\n",
            "\n",
            "\n",
            "CREATE TABLE \"Customer\" (\n",
            "\t\"CustomerId\" INTEGER NOT NULL, \n",
            "\t\"FirstName\" NVARCHAR(40) NOT NULL, \n",
            "\t\"LastName\" NVARCHAR(20) NOT NULL, \n",
            "\t\"Company\" NVARCHAR(80), \n",
            "\t\"Address\" NVARCHAR(70), \n",
            "\t\"City\" NVARCHAR(40), \n",
            "\t\"State\" NVARCHAR(40), \n",
            "\t\"Country\" NVARCHAR(40), \n",
            "\t\"PostalCode\" NVARCHAR(10), \n",
            "\t\"Phone\" NVARCHAR(24), \n",
            "\t\"Fax\" NVARCHAR(24), \n",
            "\t\"Email\" NVARCHAR(60) NOT NULL, \n",
            "\t\"SupportRepId\" INTEGER, \n",
            "\tPRIMARY KEY (\"CustomerId\"), \n",
            "\tFOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from Customer table:\n",
            "CustomerId\tFirstName\tLastName\tCompany\tAddress\tCity\tState\tCountry\tPostalCode\tPhone\tFax\tEmail\tSupportRepId\n",
            "1\tLuís\tGonçalves\tEmbraer - Empresa Brasileira de Aeronáutica S.A.\tAv. Brigadeiro Faria Lima, 2170\tSão José dos Campos\tSP\tBrazil\t12227-000\t+55 (12) 3923-5555\t+55 (12) 3923-5566\tluisg@embraer.com.br\t3\n",
            "2\tLeonie\tKöhler\tNone\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t+49 0711 2842222\tNone\tleonekohler@surfeu.de\t5\n",
            "3\tFrançois\tTremblay\tNone\t1498 rue Bélanger\tMontréal\tQC\tCanada\tH2G 1A7\t+1 (514) 721-4711\tNone\tftremblay@gmail.com\t3\n",
            "*/\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_query_checker (call_ppX7e3BcUVTpx5yANqPC5vaB)\n",
            " Call ID: call_ppX7e3BcUVTpx5yANqPC5vaB\n",
            "  Args:\n",
            "    query: SELECT e.EmployeeId, e.FirstName, e.LastName, SUM(i.Total) as TotalSales\n",
            "FROM Employee e\n",
            "JOIN Customer c ON c.SupportRepId = e.EmployeeId\n",
            "JOIN Invoice i ON i.CustomerId = c.CustomerId\n",
            "WHERE strftime('%Y', i.InvoiceDate) = '2009'\n",
            "GROUP BY e.EmployeeId, e.FirstName, e.LastName\n",
            "ORDER BY TotalSales DESC\n",
            "LIMIT 1;\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_query_checker\n",
            "\n",
            "```sql\n",
            "SELECT e.EmployeeId, e.FirstName, e.LastName, SUM(i.Total) as TotalSales\n",
            "FROM Employee e\n",
            "JOIN Customer c ON c.SupportRepId = e.EmployeeId\n",
            "JOIN Invoice i ON i.CustomerId = c.CustomerId\n",
            "WHERE strftime('%Y', i.InvoiceDate) = '2009'\n",
            "GROUP BY e.EmployeeId, e.FirstName, e.LastName\n",
            "ORDER BY TotalSales DESC\n",
            "LIMIT 1;\n",
            "```\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_query (call_RXEXno0BMpSS4dZ5bQGit94j)\n",
            " Call ID: call_RXEXno0BMpSS4dZ5bQGit94j\n",
            "  Args:\n",
            "    query: SELECT e.EmployeeId, e.FirstName, e.LastName, SUM(i.Total) as TotalSales\n",
            "FROM Employee e\n",
            "JOIN Customer c ON c.SupportRepId = e.EmployeeId\n",
            "JOIN Invoice i ON i.CustomerId = c.CustomerId\n",
            "WHERE strftime('%Y', i.InvoiceDate) = '2009'\n",
            "GROUP BY e.EmployeeId, e.FirstName, e.LastName\n",
            "ORDER BY TotalSales DESC\n",
            "LIMIT 1;\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_query\n",
            "\n",
            "[(5, 'Steve', 'Johnson', 164.33999999999997)]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The sales agent who made the most in sales in 2009 was Steve Johnson, with total sales of 164.34.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This massive code block lays the groundwork for a highly modular and resilient SQL agent. Instead of a single LLM trying to do everything, you're creating specialized functions and nodes for distinct responsibilities:\n",
        "\n",
        "  * **Schema Discovery**: Getting table information.\n",
        "  * **Query Generation**: Writing the initial SQL.\n",
        "  * **Query Checking/Correction**: Ensuring the SQL is valid and robust before execution.\n",
        "  * **Query Execution:** Running the SQL against the database.\n",
        "This multi-step approach with built-in **self-correction** (the check_query step) significantly improves the reliability and accuracy of your SQL agent, reducing \"hallucinated\" or incorrect queries. This is a common and effective pattern in advanced agent design.\n",
        "\n",
        "Instead of relying on a single, general-purpose ReAct agent for all database interactions, this code defines individual specialized nodes and their logic, which you'll later connect in a LangGraph to create a precise workflow. This approach allows for detailed control over each step of the agent's reasoning, including crucial self-correction mechanisms.\n",
        "\n",
        "1. **New Imports**\n",
        "```\n",
        "from typing import Literal # For type hints that specify exact string values\n",
        "from langchain_core.messages import AIMessage # Represents an AI's message, including tool calls\n",
        "from langchain_core.runnables import RunnableConfig # For configuration of runnables (less relevant here for explanation)\n",
        "from langgraph.graph import END, START, MessagesState, StateGraph # Core LangGraph components\n",
        "from langgraph.prebuilt import ToolNode # A specific type of LangGraph node for executing tools\n",
        "```\n",
        "`ToolNode:` This is a prebuilt `LangGraph` node type designed specifically to execute tools. When control reaches a `ToolNode`, it automatically calls the tool(s) associated with it and adds the `ToolMessage` (the output of the tool) to the state.\n",
        "\n",
        "2. **Initializing ToolNodes for Direct Tool Execution**\n",
        "```\n",
        "get_schema_tool = next(tool for tool in tools if tool.name == \"sql_db_schema\")\n",
        "get_schema_node = ToolNode([get_schema_tool], name=\"get_schema\")\n",
        "run_query_tool = next(tool for tool in tools if tool.name == \"sql_db_query\")\n",
        "run_query_node = ToolNode([run_query_tool], name=\"run_query\")\n",
        "```\n",
        " * These lines extract specific `Tool` objects from your tools list (which you obtained from `SQLDatabaseToolkit`).\n",
        " * `next(tool for tool in tools if tool.name == \"...\"):` This is a Pythonic way to find the first tool in the tools list that matches a given name.\n",
        " * `get_schema_node = ToolNode([get_schema_tool], name=\"get_schema\"):`\n",
        "    * This creates a `ToolNode` named \"get_schema\". When `LangGraph` transitions to this node, it will automatically execute the `sql_db_schema` tool. The output (the database schema) will then be available in the graph's state.\n",
        " * `run_query_node = ToolNode([run_query_tool], name=\"run_query\"):`\n",
        "    * Similarly, this creates a ToolNode named \"run_query\". When this node is activated, it will execute the sql_db_query tool, running the SQL query that was provided to it (usually by a preceding LLM step).\n",
        "\n",
        "3. **Example: Predetermined `Tool` Call (`list_tables` function)**\n",
        "```\n",
        "def list_tables(state: MessagesState):\n",
        "    tool_call = {\n",
        "        \"name\": \"sql_db_list_tables\",\n",
        "        \"args\": {},\n",
        "        \"id\": \"abc123\", # Manually creating an ID for the tool call\n",
        "        \"type\": \"tool_call\",\n",
        "    }\n",
        "    tool_call_message = AIMessage(content=\"\", tool_calls=[tool_call])\n",
        "\n",
        "    list_tables_tool = next(tool for tool in tools if tool.name == \"sql_db_list_tables\")\n",
        "    # Directly invoke the tool with the manually created tool_call\n",
        "    tool_message = list_tables_tool.invoke(tool_call)\n",
        "    response = AIMessage(f\"Available tables: {tool_message.content}\")\n",
        "\n",
        "    return {\"messages\": [tool_call_message, tool_message, response]}\n",
        "```\n",
        " * **Purpose:** This function defines a node that programmatically executes a tool call without LLM reasoning. It's useful for fixed initial steps or known actions.\n",
        "    * `tool_call = {...}:` Here, you're manually creating the dictionary representation of a tool call. This is how LangGraph (and LLMs) represent a tool invocation.\n",
        "    * `\"name\":` The name of the tool to call.\n",
        "    * `\"args\":` The arguments for the tool (empty for list_tables).\n",
        "    * `\"id\":` A unique ID for this specific tool call.\n",
        "    * `\"type\":` Indicates it's a tool_call.\n",
        " * `tool_call_message = AIMessage(content=\"\", tool_calls=[tool_call]):` An `AIMessage` typically comes from an LLM. When you programmatically make a tool call that an LLM could have made, you wrap it in an `AIMessage` to maintain consistency in the `MessagesState`.\n",
        " * `list_tables_tool.invoke(tool_call):` This directly executes the underlying Python function associated with the `sql_db_list_tables` tool, passing the `tool_call` object.\n",
        " * `tool_message = list_tables_tool.invoke(tool_call):` The result of the tool's execution (a ToolMessage) is captured.\n",
        " * `response = AIMessage(...):` A final AIMessage is created to summarize the result of the list_tables action, making it clear in the conversation history.\n",
        " * `return {\"messages\": [...]}:` The `MessagesState` is updated with the `tool_call_message`, the `tool_message` (tool output), and the summarizing response.\n",
        "\n",
        "4. **Example: Forcing a Model to Create a Tool Call (call_get_schema function)**\n",
        "```\n",
        "def call_get_schema(state: MessagesState):\n",
        "    # Bind only the get_schema_tool to the LLM and force it to pick one (since only one is available)\n",
        "    llm_with_tools = llm.bind_tools([get_schema_tool], tool_choice=\"any\")\n",
        "    response = llm_with_tools.invoke(state[\"messages\"]) # Invoke the LLM with the current messages\n",
        "\n",
        "    return {\"messages\": [response]}\n",
        "```\n",
        " * **Purpose:** This function defines a node where the **LLM is explicitly instructed** to make a tool call. This is useful for initial steps where you always want the LLM to perform a specific action, like getting schema, to inform its later reasoning.\n",
        " * `llm_with_tools = llm.bind_tools([get_schema_tool], tool_choice=\"any\"):`\n",
        "    * `llm.bind_tools([...]):` This creates a new version of your llm instance that is aware of and can call only the specified tools (here, just get_schema_tool).\n",
        "    * `tool_choice=\"any\":` This is the key. It instructs the LLM that it must **choose one** of the available tools to respond. Since only `get_schema_tool` is provided, the LLM is effectively forced to generate a `tool_call` for `sql_db_schema`.\n",
        " * `response = llm_with_tools.invoke(state[\"messages\"]):` The LLM is invoked with the current state[\"messages\"]. Its response will be an AIMessage containing the tool_call for sql_db_schema.\n",
        " * `return {\"messages\": [response]}:` The `AIMessage` with the tool call is added to the state.\n",
        "\n",
        "5. **Generating the Query (generate_query function)**\n",
        "```\n",
        "generate_query_system_prompt = \"\"\"\n",
        "You are an agent designed to interact with a SQL database.\n",
        "Given an input question, create a syntactically correct {dialect} query to run,\n",
        "then look at the results of the query and return the answer. Unless the user\n",
        "specifies a specific number of examples they wish to obtain, always limit your\n",
        "query to at most {top_k} results.\n",
        "You can order the results by a relevant column to return the most interesting\n",
        "examples in the database. Never query for all the columns from a specific table,\n",
        "only ask for the relevant columns given the question.\n",
        "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
        "\"\"\".format(\n",
        "    dialect=db.dialect,\n",
        "    top_k=5,\n",
        ")\n",
        "def generate_query(state: MessagesState):\n",
        "    system_message = {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": generate_query_system_prompt,\n",
        "    }\n",
        "    # We do not force a tool call here, to allow the model to\n",
        "    # respond naturally when it obtains the solution.\n",
        "    llm_with_tools = llm.bind_tools([run_query_tool]) # LLM can only call run_query_tool\n",
        "    response = llm_with_tools.invoke([system_message] + state[\"messages\"]) # Invoke with system prompt + current messages\n",
        "\n",
        "    return {\"messages\": [response]}\n",
        "```\n",
        " * **Purpose:** This node's responsibility is for the LLM to generate a SQL query based on the current context (including the user's initial question and any schema information gathered).\n",
        " * `generate_query_system_prompt:` This prompt specifically guides the LLM on how to generate SQL queries (limiting results, selecting relevant columns, avoiding DML, etc.).\n",
        " * `llm_with_tools = llm.bind_tools([run_query_tool]):` Here, we bind only the run_query_tool. This means the LLM's only callable action at this stage is to propose a SQL query by making a tool_call to run_query_tool. We do not use tool_choice=\"any\" here, allowing the model some flexibility, though the prompt and tool binding strongly nudge it towards a tool call.\n",
        " * `response = llm_with_tools.invoke([system_message] + state[\"messages\"]):` The LLM processes the combined messages (its system prompt plus the ongoing conversation history) and generates an AIMessage which should contain a tool_call to run_query_tool with the generated SQL query.\n",
        "\n",
        " 6. **Checking the Query (check_query function)**\n",
        "\n",
        "  ```\n",
        " check_query_system_prompt = \"\"\"\n",
        "You are a SQL expert with a strong attention to detail.\n",
        "Double check the {dialect} query for common mistakes, including:\n",
        "     - Using NOT IN with NULL values\n",
        "     - Using UNION when UNION ALL should have been used\n",
        "     - Using BETWEEN for exclusive ranges\n",
        "     - Data type mismatch in predicates\n",
        "     - Properly quoting identifiers\n",
        "     - Using the correct number of arguments for functions\n",
        "     - Casting to the correct data type\n",
        "     - Using the proper columns for joins\n",
        "If there are any of the above mistakes, rewrite the query. If there are no mistakes,\n",
        "just reproduce the original query.\n",
        "You will call the appropriate tool to execute the query after running this check.\n",
        "\"\"\".format(dialect=db.dialect)\n",
        "def check_query(state: MessagesState):\n",
        "    system_message = {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": check_query_system_prompt,\n",
        "    }\n",
        "\n",
        "    # Extract the previously generated tool call (which contains the SQL query)\n",
        "    tool_call = state[\"messages\"][-1].tool_calls[0]\n",
        "    # Create an artificial user message with the query for the LLM to check\n",
        "    user_message = {\"role\": \"user\", \"content\": tool_call[\"args\"][\"query\"]}\n",
        "\n",
        "    # Bind the run_query_tool and force the LLM to make a tool choice (either re-run or correct)\n",
        "    llm_with_tools = llm.bind_tools([run_query_tool], tool_choice=\"any\")\n",
        "    # Invoke the LLM with the check prompt and the query to be checked\n",
        "    response = llm_with_tools.invoke([system_message, user_message])\n",
        "    # IMPORTANT: Ensure the ID of the new tool_call matches the original one for LangGraph tracking\n",
        "    response.id = state[\"messages\"][-1].id\n",
        "\n",
        "    return {\"messages\": [response]}\n",
        "```\n",
        "\n",
        " * **Purpose:** This is a powerful **self-correction** mechanism. After generate_query proposes a SQL query, this node uses a separate LLM invocation to act as a \"SQL expert\" and critically review that query for common errors.\n",
        " * `check_query_system_prompt:` This detailed prompt explicitly lists common SQL pitfalls the LLM should look for. It instructs the LLM to either rewrite the query if mistakes are found or just reproduce it if it's correct. It also explicitly tells it to call a tool (which implies run_query_tool).\n",
        " * `tool_call = state[\"messages\"][-1].tool_calls[0]:` This line retrieves the last AIMessage from the state, which is expected   to contain the tool call (with the SQL query) generated by the generate_query node. It then extracts that tool call.\n",
        " * `user_message = {\"role\": \"user\", \"content\": tool_call[\"args\"][\"query\"]}:` A new \"user\" message is constructed. Its content is only the SQL query that needs to be checked. This focuses the checking LLM solely on the query itself.\n",
        " * `llm_with_tools = llm.bind_tools([run_query_tool], tool_choice=\"any\"):`\n",
        "  Again, the run_query_tool is bound, and tool_choice=\"any\" is used. This forces the checking LLM to output a tool_call containing the (potentially corrected) query.\n",
        " * `response = llm_with_tools.invoke([system_message, user_message]):` The checking LLM processes its system prompt (check_query_system_prompt) and the specific user_message containing the query to be checked.\n",
        "\n",
        " * `response.id = state[\"messages\"][-1].id:` This is a very important line! If the checking LLM rewrites the query, it will generate a new tool call ID. However, for LangGraph to correctly update the original tool call (from generate_query) with the checked/corrected one, the ID of the AIMessage containing the corrected tool call must match the ID of the original tool call that it's replacing. This ensures a seamless continuation of the tool execution.\n",
        " * `return {\"messages\": [response]}:` The AIMessage containing the (checked or corrected) tool_call for run_query_tool is added to the state."
      ],
      "metadata": {
        "id": "5mxvs9TgCCfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal # For type hints that specify exact string values\n",
        "from langchain_core.messages import AIMessage # Represents an AI's message, including tool calls\n",
        "from langchain_core.runnables import RunnableConfig # For configuration of runnables (less relevant here for explanation)\n",
        "from langgraph.graph import END, START, MessagesState, StateGraph # Core LangGraph components\n",
        "from langgraph.prebuilt import ToolNode # A specific type of LangGraph node for executing tools\n",
        "\n",
        "\n",
        "get_schema_tool = next(tool for tool in tools if tool.name == \"sql_db_schema\")\n",
        "get_schema_node = ToolNode([get_schema_tool], name=\"get_schema\")\n",
        "\n",
        "run_query_tool = next(tool for tool in tools if tool.name == \"sql_db_query\")\n",
        "run_query_node = ToolNode([run_query_tool], name=\"run_query\")\n",
        "\n",
        "\n",
        "# Example: create a predetermined tool call\n",
        "def list_tables(state: MessagesState):\n",
        "    tool_call = {\n",
        "        \"name\": \"sql_db_list_tables\",\n",
        "        \"args\": {},\n",
        "        \"id\": \"abc123\",\n",
        "        \"type\": \"tool_call\",\n",
        "    }\n",
        "    tool_call_message = AIMessage(content=\"\", tool_calls=[tool_call])\n",
        "\n",
        "    list_tables_tool = next(tool for tool in tools if tool.name == \"sql_db_list_tables\")\n",
        "    tool_message = list_tables_tool.invoke(tool_call)\n",
        "    response = AIMessage(f\"Available tables: {tool_message.content}\")\n",
        "\n",
        "    return {\"messages\": [tool_call_message, tool_message, response]}\n",
        "\n",
        "\n",
        "# Example: force a model to create a tool call\n",
        "def call_get_schema(state: MessagesState):\n",
        "    # Note that LangChain enforces that all models accept `tool_choice=\"any\"`\n",
        "    # as well as `tool_choice=<string name of tool>`.\n",
        "    llm_with_tools = llm.bind_tools([get_schema_tool], tool_choice=\"any\")\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "generate_query_system_prompt = \"\"\"\n",
        "You are an agent designed to interact with a SQL database.\n",
        "Given an input question, create a syntactically correct {dialect} query to run,\n",
        "then look at the results of the query and return the answer. Unless the user\n",
        "specifies a specific number of examples they wish to obtain, always limit your\n",
        "query to at most {top_k} results.\n",
        "\n",
        "You can order the results by a relevant column to return the most interesting\n",
        "examples in the database. Never query for all the columns from a specific table,\n",
        "only ask for the relevant columns given the question.\n",
        "\n",
        "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
        "\"\"\".format(\n",
        "    dialect=db.dialect,\n",
        "    top_k=5,\n",
        ")\n",
        "\n",
        "\n",
        "def generate_query(state: MessagesState):\n",
        "    system_message = {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": generate_query_system_prompt,\n",
        "    }\n",
        "    # We do not force a tool call here, to allow the model to\n",
        "    # respond naturally when it obtains the solution.\n",
        "    llm_with_tools = llm.bind_tools([run_query_tool])\n",
        "    response = llm_with_tools.invoke([system_message] + state[\"messages\"])\n",
        "\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "check_query_system_prompt = \"\"\"\n",
        "You are a SQL expert with a strong attention to detail.\n",
        "Double check the {dialect} query for common mistakes, including:\n",
        "- Using NOT IN with NULL values\n",
        "- Using UNION when UNION ALL should have been used\n",
        "- Using BETWEEN for exclusive ranges\n",
        "- Data type mismatch in predicates\n",
        "- Properly quoting identifiers\n",
        "- Using the correct number of arguments for functions\n",
        "- Casting to the correct data type\n",
        "- Using the proper columns for joins\n",
        "\n",
        "If there are any of the above mistakes, rewrite the query. If there are no mistakes,\n",
        "just reproduce the original query.\n",
        "\n",
        "You will call the appropriate tool to execute the query after running this check.\n",
        "\"\"\".format(dialect=db.dialect)\n",
        "\n",
        "\n",
        "def check_query(state: MessagesState):\n",
        "    system_message = {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": check_query_system_prompt,\n",
        "    }\n",
        "\n",
        "    # Generate an artificial user message to check\n",
        "    tool_call = state[\"messages\"][-1].tool_calls[0]\n",
        "    user_message = {\"role\": \"user\", \"content\": tool_call[\"args\"][\"query\"]}\n",
        "    llm_with_tools = llm.bind_tools([run_query_tool], tool_choice=\"any\")\n",
        "    response = llm_with_tools.invoke([system_message, user_message])\n",
        "    response.id = state[\"messages\"][-1].id\n",
        "\n",
        "    return {\"messages\": [response]}"
      ],
      "metadata": {
        "id": "CVPdOyiPso1j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Complete Workflow of Your SQL Agent:**\n",
        "1. Start: User asks a question (e.g., \"How many artists are there?\").\n",
        "2. List Tables (list_tables): Agent first gets a list of all tables in the database.\n",
        "3. Call Get Schema (call_get_schema): Agent then requests the schema for relevant tables (e.g., Artist table).\n",
        "4. Get Schema (Execute Tool) (get_schema): The sql_db_schema tool is actually executed, and the schema details are added to the state.\n",
        "5. Generate Query (generate_query): The LLM, with the user's question and schema info, generates a SQL query (e.g., SELECT COUNT(*) FROM Artist;).\n",
        "Conditional Check (should_continue):\n",
        "  * If the LLM provided a SQL query, go to check_query.\n",
        "  * If the LLM provided a direct answer (no tool call), END.\n",
        "6. Check Query (check_query): The LLM reviews the generated SQL query for correctness and common errors, potentially rewriting it.\n",
        "7. Run Query (run_query): The (checked/corrected) SQL query is executed against the Chinook.db database. The results are added to the state.\n",
        "8. Loop Back to Generate Query (run_query -> generate_query): The agent returns to the generate_query step. The LLM now sees the results of the query it just ran. It can use these results to either formulate a final answer or decide it needs to execute another query (and loop through check/run again) to fully answer the user's question.\n",
        "9. Loop Continues or Ends: This loop continues until the generate_query node produces a final answer without a tool call, at which point the should_continue function leads to END.\n",
        "\n",
        "This piece of code brings together all the individual nodes and functions you defined previously and connects them to form the complete, intelligent, self-correcting SQL Agent workflow using LangGraph.\n",
        "\n",
        "1. `should_continue` Function (Conditional Router)\n",
        "```\n",
        "def should_continue(state: MessagesState) -> Literal[END, \"check_query\"]:\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    if not last_message.tool_calls: # If the last message does NOT contain tool calls\n",
        "        return END # The agent thinks it has a final answer\n",
        "    else: # If the last message DOES contain tool calls (meaning a query was generated)\n",
        "        return \"check_query\" # Go to the query checking step\n",
        "```\n",
        "  * **Purpose:** This function acts as a router or a decision point within your LangGraph. After a specific node (in this case, generate_query) completes its execution, LangGraph calls this should_continue function to determine what the next step in the workflow should be.\n",
        "  * **Input:** It receives the current state of the graph, which includes the messages list.\n",
        "  * **Logic**:\n",
        "    * It looks at the last_message in the state[\"messages\"].\n",
        "    * if not last_message.tool_calls:: This is the core condition. If the last message from the generate_query LLM does not contain any tool calls, it means the LLM has concluded that it has successfully answered the user's question or can't proceed with another query. In this scenario, the graph's execution should END.\n",
        "    * else: return \"check_query\": If the last_message does contain tool_calls (specifically, a call to run_query_tool with a generated SQL query), it means the generate_query node has proposed a SQL query. In this case, the should_continue function tells LangGraph to transition to the \"check_query\" node, where that proposed SQL query will be reviewed for errors.\n",
        "  * `-> Literal[END, \"check_query\"]:` This is a type hint indicating that the function is expected to return either the END constant or the string \"check_query\", which are valid node names (or END signal) in LangGraph.\n",
        "\n",
        "2. `**Building the Graph** (builder = StateGraph(MessagesState))`\n",
        "This section defines the entire flow and connections between the nodes.\n",
        "\n",
        "* `builder = StateGraph(MessagesState):`\n",
        "  * Initializes a StateGraph, which is the core object for defining your graph's structure. It uses MessagesState to maintain the conversational history across all nodes.\n",
        "* `builder.add_node(list_tables):`\n",
        "  * Adds the list_tables function (which programmatically calls sql_db_list_tables) as a node in the graph. The node will be named \"list_tables\" implicitly by its function name.\n",
        "* `builder.add_node(call_get_schema):`\n",
        "  * Adds the call_get_schema function (which forces the LLM to call sql_db_schema) as a node named \"call_get_schema\".\n",
        "* `builder.add_node(get_schema_node, \"get_schema\"):`\n",
        "  * Adds the ToolNode you created earlier for directly executing sql_db_schema. It's explicitly named \"get_schema\" here.\n",
        "* `builder.add_node(generate_query):`\n",
        " * Adds the generate_query function (where the LLM attempts to write a SQL query) as a node named \"generate_query\".\n",
        "* `builder.add_node(check_query):`\n",
        " * Adds the check_query function (where the LLM reviews and potentially corrects the SQL query) as a node named \"check_query\".\n",
        "* `builder.add_node(run_query_node, \"run_query\"):`\n",
        "  * Adds the ToolNode you created earlier for directly executing sql_db_query. It's explicitly named \"run_query\".\n",
        "\n",
        "3. **Defining Edges** (Flow of Control)\n",
        "Edges define how control passes from one node to another.\n",
        "\n",
        "* `builder.add_edge(START, \"list_tables\"):`\n",
        "\n",
        "  * **Initial Entry Point:** When the graph starts (i.e., when you provide the initial user query), the execution begins by calling the list_tables node. This ensures the agent always starts by understanding the available tables.\n",
        "* `builder.add_edge(\"list_tables\", \"call_get_schema\"):`\n",
        "  * After the list_tables node completes, control immediately passes to the call_get_schema node. This forces the agent to then obtain schema details (which will be crucial for writing accurate queries).\n",
        "* `builder.add_edge(\"call_get_schema\", \"get_schema\"):`\n",
        "  * After call_get_schema (which generated a tool call for sql_db_schema), control passes to the get_schema node (the ToolNode that executes that tool call).\n",
        "* `builder.add_edge(\"get_schema\", \"generate_query\"):`\n",
        "   * Once the schema information has been retrieved (by get_schema_node), control moves to the generate_query node, where the LLM will attempt to formulate a SQL query based on the user's input and the newly acquired schema knowledge.\n",
        "* `builder.add_conditional_edges(\"generate_query\", should_continue):`\n",
        "   * This is where the dynamic routing happens. After the generate_query node finishes, the should_continue function is invoked.\n",
        "   * If should_continue returns END (meaning the LLM has a final answer), the graph terminates.\n",
        "   * If should_continue returns \"check_query\" (meaning the LLM proposed a SQL query), control is passed to the check_query node for verification.\n",
        "* `builder.add_edge(\"check_query\", \"run_query\"):`\n",
        "   * If the query passes (or is corrected by) the check_query node, control then moves to the run_query node (the ToolNode that executes the sql_db_query tool).\n",
        "* `builder.add_edge(\"run_query\", \"generate_query\"):`\n",
        "   * This creates a crucial loop for iteration and self-correction. After the run_query node executes the SQL query (and the result is added to the state), control is passed back to the generate_query node. This allows the LLM to:\n",
        "      * See the results of the query it just ran.\n",
        "      * Decide if the results are sufficient to answer the question, or if it needs to run another query (perhaps to refine the answer or explore further based on the initial results).\n",
        "      * Potentially generate a final answer (leading to END via should_continue next time).\n",
        "4. `agent = builder.compile()`\n",
        "  * This is the final step. It takes the entire graph definition (nodes and edges) and compiles it into a runnable LangGraph agent object. This agent is now ready to take inputs and execute the sophisticated SQL interaction workflow."
      ],
      "metadata": {
        "id": "0TWvT_bJ2xyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def should_continue(state: MessagesState) -> Literal[END, \"check_query\"]:\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    if not last_message.tool_calls:\n",
        "        return END\n",
        "    else:\n",
        "        return \"check_query\"\n",
        "\n",
        "\n",
        "builder = StateGraph(MessagesState)\n",
        "builder.add_node(list_tables)\n",
        "builder.add_node(call_get_schema)\n",
        "builder.add_node(get_schema_node, \"get_schema\")\n",
        "builder.add_node(generate_query)\n",
        "builder.add_node(check_query)\n",
        "builder.add_node(run_query_node, \"run_query\")\n",
        "\n",
        "builder.add_edge(START, \"list_tables\")\n",
        "builder.add_edge(\"list_tables\", \"call_get_schema\")\n",
        "builder.add_edge(\"call_get_schema\", \"get_schema\")\n",
        "builder.add_edge(\"get_schema\", \"generate_query\")\n",
        "builder.add_conditional_edges(\n",
        "    \"generate_query\",\n",
        "    should_continue,\n",
        ")\n",
        "builder.add_edge(\"check_query\", \"run_query\")\n",
        "builder.add_edge(\"run_query\", \"generate_query\")\n",
        "\n",
        "agent = builder.compile()"
      ],
      "metadata": {
        "id": "oFVs9AuYsrwg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "\n",
        "display(Image(agent.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "VSPW8lvAsuKn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "outputId": "5a1aa3aa-b54d-459c-b61a-baed8a286821"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Which sales agent made the most in sales in 2009?\"\n",
        "\n",
        "for step in agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "5Yl-7cShsxGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6dd160b-4494-4b61-a510-cc3213518b4b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Which sales agent made the most in sales in 2009?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Available tables: Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_schema (call_p9F2ygxhSVL7tg6G2HgkEnyp)\n",
            " Call ID: call_p9F2ygxhSVL7tg6G2HgkEnyp\n",
            "  Args:\n",
            "    table_names: Employee, Invoice, InvoiceLine\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_schema\n",
            "\n",
            "\n",
            "CREATE TABLE \"Employee\" (\n",
            "\t\"EmployeeId\" INTEGER NOT NULL, \n",
            "\t\"LastName\" NVARCHAR(20) NOT NULL, \n",
            "\t\"FirstName\" NVARCHAR(20) NOT NULL, \n",
            "\t\"Title\" NVARCHAR(30), \n",
            "\t\"ReportsTo\" INTEGER, \n",
            "\t\"BirthDate\" DATETIME, \n",
            "\t\"HireDate\" DATETIME, \n",
            "\t\"Address\" NVARCHAR(70), \n",
            "\t\"City\" NVARCHAR(40), \n",
            "\t\"State\" NVARCHAR(40), \n",
            "\t\"Country\" NVARCHAR(40), \n",
            "\t\"PostalCode\" NVARCHAR(10), \n",
            "\t\"Phone\" NVARCHAR(24), \n",
            "\t\"Fax\" NVARCHAR(24), \n",
            "\t\"Email\" NVARCHAR(60), \n",
            "\tPRIMARY KEY (\"EmployeeId\"), \n",
            "\tFOREIGN KEY(\"ReportsTo\") REFERENCES \"Employee\" (\"EmployeeId\")\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from Employee table:\n",
            "EmployeeId\tLastName\tFirstName\tTitle\tReportsTo\tBirthDate\tHireDate\tAddress\tCity\tState\tCountry\tPostalCode\tPhone\tFax\tEmail\n",
            "1\tAdams\tAndrew\tGeneral Manager\tNone\t1962-02-18 00:00:00\t2002-08-14 00:00:00\t11120 Jasper Ave NW\tEdmonton\tAB\tCanada\tT5K 2N1\t+1 (780) 428-9482\t+1 (780) 428-3457\tandrew@chinookcorp.com\n",
            "2\tEdwards\tNancy\tSales Manager\t1\t1958-12-08 00:00:00\t2002-05-01 00:00:00\t825 8 Ave SW\tCalgary\tAB\tCanada\tT2P 2T3\t+1 (403) 262-3443\t+1 (403) 262-3322\tnancy@chinookcorp.com\n",
            "3\tPeacock\tJane\tSales Support Agent\t2\t1973-08-29 00:00:00\t2002-04-01 00:00:00\t1111 6 Ave SW\tCalgary\tAB\tCanada\tT2P 5M5\t+1 (403) 262-3443\t+1 (403) 262-6712\tjane@chinookcorp.com\n",
            "*/\n",
            "\n",
            "\n",
            "CREATE TABLE \"Invoice\" (\n",
            "\t\"InvoiceId\" INTEGER NOT NULL, \n",
            "\t\"CustomerId\" INTEGER NOT NULL, \n",
            "\t\"InvoiceDate\" DATETIME NOT NULL, \n",
            "\t\"BillingAddress\" NVARCHAR(70), \n",
            "\t\"BillingCity\" NVARCHAR(40), \n",
            "\t\"BillingState\" NVARCHAR(40), \n",
            "\t\"BillingCountry\" NVARCHAR(40), \n",
            "\t\"BillingPostalCode\" NVARCHAR(10), \n",
            "\t\"Total\" NUMERIC(10, 2) NOT NULL, \n",
            "\tPRIMARY KEY (\"InvoiceId\"), \n",
            "\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from Invoice table:\n",
            "InvoiceId\tCustomerId\tInvoiceDate\tBillingAddress\tBillingCity\tBillingState\tBillingCountry\tBillingPostalCode\tTotal\n",
            "1\t2\t2009-01-01 00:00:00\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t1.98\n",
            "2\t4\t2009-01-02 00:00:00\tUllevålsveien 14\tOslo\tNone\tNorway\t0171\t3.96\n",
            "3\t8\t2009-01-03 00:00:00\tGrétrystraat 63\tBrussels\tNone\tBelgium\t1000\t5.94\n",
            "*/\n",
            "\n",
            "\n",
            "CREATE TABLE \"InvoiceLine\" (\n",
            "\t\"InvoiceLineId\" INTEGER NOT NULL, \n",
            "\t\"InvoiceId\" INTEGER NOT NULL, \n",
            "\t\"TrackId\" INTEGER NOT NULL, \n",
            "\t\"UnitPrice\" NUMERIC(10, 2) NOT NULL, \n",
            "\t\"Quantity\" INTEGER NOT NULL, \n",
            "\tPRIMARY KEY (\"InvoiceLineId\"), \n",
            "\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \n",
            "\tFOREIGN KEY(\"InvoiceId\") REFERENCES \"Invoice\" (\"InvoiceId\")\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from InvoiceLine table:\n",
            "InvoiceLineId\tInvoiceId\tTrackId\tUnitPrice\tQuantity\n",
            "1\t1\t2\t0.99\t1\n",
            "2\t1\t4\t0.99\t1\n",
            "3\t2\t6\t0.99\t1\n",
            "*/\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_query (call_a86vYBA9ojSk4EVLFFHoIz7Q)\n",
            " Call ID: call_a86vYBA9ojSk4EVLFFHoIz7Q\n",
            "  Args:\n",
            "    query: SELECT e.EmployeeId, e.FirstName, e.LastName, SUM(i.Total) AS TotalSales\n",
            "FROM Employee e\n",
            "JOIN Customer c ON c.SupportRepId = e.EmployeeId\n",
            "JOIN Invoice i ON i.CustomerId = c.CustomerId\n",
            "WHERE strftime('%Y', i.InvoiceDate) = '2009'\n",
            "GROUP BY e.EmployeeId, e.FirstName, e.LastName\n",
            "ORDER BY TotalSales DESC\n",
            "LIMIT 1;\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  sql_db_query (call_MNCY0shlMdJnzfAx9CppzgiZ)\n",
            " Call ID: call_MNCY0shlMdJnzfAx9CppzgiZ\n",
            "  Args:\n",
            "    query: SELECT e.EmployeeId, e.FirstName, e.LastName, SUM(i.Total) AS TotalSales\n",
            "FROM Employee e\n",
            "JOIN Customer c ON c.SupportRepId = e.EmployeeId\n",
            "JOIN Invoice i ON i.CustomerId = c.CustomerId\n",
            "WHERE strftime('%Y', i.InvoiceDate) = '2009'\n",
            "GROUP BY e.EmployeeId, e.FirstName, e.LastName\n",
            "ORDER BY TotalSales DESC\n",
            "LIMIT 1;\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: sql_db_query\n",
            "\n",
            "[(5, 'Steve', 'Johnson', 164.33999999999997)]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The sales agent who made the most in sales in 2009 was Steve Johnson, with total sales of 164.34.\n"
          ]
        }
      ]
    }
  ]
}