{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyr/Q1l6lYJ6gHz+YCL5Hf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahalingamagesthian/learningai/blob/main/09_SupervisorAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This page is inspired from https://langchain-ai.github.io/langgraph/tutorials/multi_agent/agent_supervisor/\n",
        "\n",
        "# Goal\n",
        "creating a supervisor agent step into more advanced, multi-agent AI systems\n",
        "\n",
        "This `pip install` command is simply setting up your Python environment by installing (or updating) the necessary libraries. Let's break down each part:\n",
        "\n",
        "1. `pip install:`\n",
        "\n",
        "  * `pip`: This is Python's **standard package** installer. Think of it as a tool that helps you download and set up pre-written code (libraries or packages) from the internet (specifically, from PyPI - the Python Package Index) so you can use them in your own Python projects.\n",
        "  * `install`: This command tells `pip` to go ahead and fetch those specified packages and make them available for your Python programs.\n",
        "\n",
        "2. `-U (or --upgrade)`:\n",
        "\n",
        "  * This is an option for the install command.\n",
        "  * It stands for `\"upgrade\"`. If any of these packages are already installed on your system, `pip` will upgrade them to their latest compatible versions. This is good practice to ensure you're using the most up-to-date features and bug fixes.\n",
        "\n",
        "3. `langgraph:`\n",
        "\n",
        "  * `What it is:` This is a powerful library for **building stateful, multi-actor applications** with LLMs.\n",
        "  * `Why it's important for AI Engineering:` It allows you to define complex workflows (like the RAG agent you just built!) where different `\"actors\"` (which could be LLMs, tools, or other agents) interact sequentially or conditionally, maintaining a shared \"state\" (memory) as they go. It's essential for creating autonomous agents that can perform multi-step reasoning and interaction.\n",
        "\n",
        "4. `langgraph-supervisor`:\n",
        "\n",
        "  * `What it is`: This is a specific extension or module built on top of `langgraph`. It provides functionality directly related to creating supervisor agents.\n",
        "  * `Why it's important for AI Engineering (and your goal):` A supervisor agent is essentially a `\"manager\"` LLM or a control mechanism that oversees the operations of multiple other `\"worker\"` agents. It decides which worker agent should act next based on the current goal and the state of the conversation. This is a common and effective pattern for tackling complex problems by breaking them down and assigning them to specialized sub-agents. You'll be using this to build your supervisor!\n",
        "\n",
        "5. langchain-tavily:\n",
        "\n",
        "   * `What it is`: This is a LangChain integration for **Tavily**, which is a search API specifically designed for AI agents.\n",
        "   * `Why it's important for AI Engineering:` In the world of AI agents, they often need access to up-to-date, real-world information. While RAG (Retrieval-Augmented Generation) from your own documents is great, sometimes you need to perform live web searches. Tavily provides a robust, real-time search capability that agents can use as a tool to find information beyond their internal knowledge base. This significantly enhances their capabilities.\n",
        "6. `langchain[openai]`:\n",
        "\n",
        "   * `langchain`: This is the foundational framework for developing applications powered by language models. It provides standard interfaces for interacting with LLMs, managing prompts, chaining operations, integrating tools, and building agents. Your RAG agent utilized many LangChain components.\n",
        "   * `[openai]`: This part is called an `\"extra\"` or `\"optional dependency.\"` It means that you're installing the core langchain library, plus additional components specifically for integrating with OpenAI's models (`like GPT-4o, GPT-4.1-mini, etc.)`. This ensures all the necessary drivers and utilities for communicating with OpenAI's API are installed."
      ],
      "metadata": {
        "id": "5rAmVEPjBEwF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba9LS2sQHrCj"
      },
      "outputs": [],
      "source": [
        "pip install -U langgraph langgraph-supervisor langchain-tavily \"langchain[openai]\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n",
        "def _set_if_undefined(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
        "\n",
        "\n",
        "_set_if_undefined(\"OPENAI_API_KEY\")\n",
        "_set_if_undefined(\"TAVILY_API_KEY\")"
      ],
      "metadata": {
        "id": "7Vc54a24H1Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This snippet provides a clear, concise example of how to programmatically perform a web search using Tavily (via LangChain's integration). It shows how to:\n",
        "  * Set up the search tool.\n",
        "  * Execute a query.\n",
        "  * Access and print specific parts of the structured search results.\n",
        "\n",
        "This is a fundamental building block for giving your AI agents the ability to look up real-time information from the internet, extending their knowledge beyond their training data or static vector stores.\n",
        "\n",
        "# Detailed Explanation:\n",
        "1. `from langchain_tavily import TavilySearch`\n",
        "\n",
        "    * `from langchain_tavily:` This part imports from the specific Python package you just installed for Tavily integration (langchain-tavily).\n",
        "    * `import TavilySearch:` This imports the TavilySearch class. This class is a \"wrapper\" or \"connector\" provided by LangChain that knows how to talk to the Tavily Search API. It abstracts away the complex details of making API requests, handling responses, etc. You just tell it what to search for, and it handles the communication with Tavily.\n",
        "2. `web_search = TavilySearch(max_results=3)`\n",
        "\n",
        "    * `web_search =:` You are creating an instance (an object) of the TavilySearch class and assigning it to the variable web_search. Think of web_search as your configured \"Tavily Search tool\" now.\n",
        "    * `TavilySearch(...):` When you create this object, you can pass parameters to configure how it behaves.\n",
        "    * `max_results=3:` This is a crucial parameter. It tells Tavily Search to return at most 3 search results for any query you make using this web_search object. This is useful for controlling the amount of information returned, especially when you're feeding it to an LLM, as more data can cost more tokens and sometimes lead to information overload.\n",
        "    * Important Note (Implicit): For this line to work, you must have your TAVILY_API_KEY set up as an environment variable (e.g., os.environ[\"TAVILY_API_KEY\"] = \"your_key_here\") or passed directly as a parameter. The TavilySearch class will automatically look for this key to authenticate your requests to the Tavily API.\n",
        "3. `web_search_results = web_search.invoke(\"who is the mayor of NYC?\")`\n",
        "\n",
        "    * `web_search_results =:` This variable will store the results returned by the web search.\n",
        "    * `web_search.invoke(...):` This is the method that actually executes the web search.\n",
        "      * In LangChain, invoke() is a standard method part of the `Runnable interface`. It means \"run this component with the given input and return the result.\"\n",
        "      * \"who is the mayor of NYC?\": This is the search query that you are sending to the Tavily Search API.\n",
        "    * `What invoke() returns:` When invoke() completes, web_search_results will be a Python dictionary. This dictionary contains the structured results from Tavily. A common structure is:\n",
        "```\n",
        "{\n",
        "    \"query\": \"who is the mayor of NYC?\",\n",
        "    \"results\": [\n",
        "        {\n",
        "            \"url\": \"...\",\n",
        "            \"content\": \"...\", // The main content/snippet of the result\n",
        "            \"title\": \"...\"\n",
        "        },\n",
        "        {\n",
        "            \"url\": \"...\",\n",
        "            \"content\": \"...\",\n",
        "            \"title\": \"...\"\n",
        "        },\n",
        "        // ... up to 3 results due to max_results=3\n",
        "    ],\n",
        "    // ... other metadata\n",
        "}\n",
        "```\n",
        "4. `print(web_search_results[\"results\"][0][\"content\"])`\n",
        "\n",
        " * This line is designed to extract and print a specific piece of information from the `web_search_results` dictionary.\n",
        " * `web_search_results[\"results\"]:` This accesses the value associated with the key \"results\" in the dictionary. This value is a list of individual search result dictionaries.\n",
        " * `[0]`: This is list indexing. It selects the first item (the first search result) from that list of results.\n",
        " * `[\"content\"]`: This accesses the value associated with the key \"content\" within that first search result dictionary. This content key typically holds the most relevant text snippet or a summarized piece of information extracted from the search result, which is often what an LLM would need.\n",
        " * `print(...):` Finally, this displays the extracted content to your console."
      ],
      "metadata": {
        "id": "kq2JRTSFRulV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_tavily import TavilySearch\n",
        "\n",
        "web_search = TavilySearch(max_results=3)\n",
        "web_search_results = web_search.invoke(\"who is the chief minister of Karnataka?\")\n",
        "\n",
        "print(web_search_results[\"results\"][0][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMk0DYxdH7eH",
        "outputId": "e3c9a6dd-20b2-46e3-c2c4-1326f21bfbe4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Siddaramaiah is an Indian politician and present Chief Minister of Karnataka. He got inducted into the Chief Minister position of Karnataka after winning the state legislative assembly elections\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This `research_agent` is a specialized AI \"employee\" in your future \"AI company.\"\n",
        "\n",
        " * It's powered by an LLM (`gpt-4.1/gpt-4o`).\n",
        " * Its only skill is performing web searches (`web_search`).\n",
        " * It knows its job (research only, no math).\n",
        " * It knows how to communicate its findings back to its manager (the supervisor) in a clear, concise way.\n",
        " * It has a specific name (`\"research_agent\"`) so the supervisor can call upon it when research is needed.\n",
        "This is a fundamental building block for your supervisor agent, enabling it to delegate specific tasks to specialized AI workers!\n",
        "\n",
        "1. `from langgraph.prebuilt import create_react_agent`\n",
        " * `langgraph.prebuilt`: `LangGraph` provides some ready-to-use (prebuilt) components and patterns to make common agent setups easier.\n",
        " * `create_react_agent:` This is a convenience function that helps you quickly set up an agent that follows the **ReAct (Reasoning and Acting)** pattern.\n",
        "    * **ReAct Agents:** These agents are designed to reason about what to do next and then act by using tools. They observe an input, decide if they need a tool, if so, they formulate arguments for the tool, execute it, observe the tool's output, and then repeat the cycle (reason, act, observe) until they have enough information to respond to the user (or, in this case, the supervisor).\n",
        "2. `research_agent = create_react_agent(...)`\n",
        "  * You are creating an instance of a ReAct agent and assigning it to the variable `research_agent`. This `research_agent` is now a fully functional, callable AI component within your `LangGraph` workflow.\n",
        "3. `Parameters of create_react_agent:`\n",
        "  * `model=\"openai:gpt-4.1\":` This specifies the Large Language Model (LLM) that will serve as the \"brain\" for this particular `research_agent`. It's the LLM that will perform the \"reasoning\" part of the ReAct cycle.\n",
        "  * Note: `gpt-4.1` might be a placeholder in your course. For a real-world scenario, you'd typically use a currently available model like `openai:gpt-4o`, `openai:gpt-4-turbo`, or `openai:gpt-3.5-turbo`. Each agent in a multi-agent system can potentially be powered by a different LLM, allowing you to choose the best model for a specific task (e.g., a cheaper, faster model for simple tasks, and a more powerful one for complex reasoning).\n",
        "  * `tools=[web_search]:`\n",
        "    * This is a **critical parameter** for any agent that needs to interact with the outside world.\n",
        "    * It's a list of Runnable objects (which `web_search` is, as it uses the .invoke() method).\n",
        "    * By providing [web_search], you are telling the `research_agent` that its only available tool is the `web_search` object (your TavilySearch instance).\n",
        "    * This means if the `research_agent` decides it needs to find information online, it knows how to call `web_search` with a specific query.\n",
        " * `prompt=(...):`\n",
        "    * This is the system prompt that defines the `research_agent's` persona, capabilities, and strict instructions. This prompt guides the LLM's behavior.\n",
        "    * `\"You are a research agent.\\n\\n\":` Establishes its identity.\n",
        "    * `\"INSTRUCTIONS:\\n- Assist ONLY with research-related tasks, DO NOT do any math\\n\":`\n",
        "      * This explicitly sets the agent's scope and limitations. In a `multi-agent` system, this is vital. The supervisor needs to know what each worker can and cannot do. This prevents the research agent from trying to solve math problems when there might be a separate `\"math_agent\"` for that.\n",
        "    * `- After you're done with your tasks, respond to the supervisor directly\\n:`\n",
        "      * This is a key instruction for multi-agent communication. It tells the `research_agent` how to signal that it has completed its specialized task.\n",
        "      * When it's finished, it shouldn't just respond to the user; it should formulate its final output specifically for the supervisor to process.\n",
        "\n",
        "    * `- Respond ONLY with the results of your work, do NOT include ANY other text.:`\n",
        "      * This enforces a clean, parseable output format. The supervisor will need to understand the research_agent's results, so clear, unembellished output makes the supervisor's job easier.\n",
        "      * It prevents the agent from adding conversational fluff like \"Okay, I have found the answer!\" and instead just provides the answer itself.\n",
        "   * `name=\"research_agent\":`\n",
        "    * This assigns a unique identifier to this agent.\n",
        "    * In a multi-agent system, the supervisor agent (which you'll define later) needs a way to refer to and select specific worker agents. This name will be used for that purpose.\n"
      ],
      "metadata": {
        "id": "AqRzMxbFMAZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "research_agent = create_react_agent(\n",
        "    model=\"openai:gpt-4.1\", # The LLM powering this agent\n",
        "    tools=[web_search], # The tools this agent has access to\n",
        "    prompt=(  # The system prompt defining its role and instructions\n",
        "        \"You are a research agent.\\n\\n\"\n",
        "        \"INSTRUCTIONS:\\n\"\n",
        "        \"- Assist ONLY with research-related tasks, DO NOT do any math\\n\"\n",
        "        \"- After you're done with your tasks, respond to the supervisor directly\\n\"\n",
        "        \"- Respond ONLY with the results of your work, do NOT include ANY other text.\"\n",
        "    ),\n",
        "    name=\"research_agent\", # A unique name for this agent\n",
        ")"
      ],
      "metadata": {
        "id": "uxRCrZtLIFGE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This snippet is a vital step because it:\n",
        " * `Validates the Worker Agent:` It confirms that your `research_agent` is correctly configured, can access and use its `web_search` tool, and can formulate an answer based on tool outputs.\n",
        " * `Demonstrates ReAct Pattern:` You are literally seeing the `\"Reason\" (decide to call tool) and \"Act\" (tool output, then final answer)` phases of a ReAct agent.\n",
        " * `Prepares for Supervisor:` Knowing that your worker agent functions correctly in isolation is crucial before you introduce the supervisor, which will orchestrate multiple such agents. You build reliable components first, then assemble them.\n",
        "\n",
        "# Step-by-Step Flow of a ReAct Agent:\n",
        "\n",
        "When you execute this code, you'll see a sequence of updates, each representing a `\"thought\"` or `\"action\"` by the `research_agent`. This is the core ReAct loop in action:\n",
        "\n",
        "   1.  **Initial Input:** The `research_agent` receives the user message: `\"who is the mayor of NYC?\"`\n",
        "   2. `Chunk 1: research_agent's Reasoning (Thought)`\n",
        "\n",
        "     * The `research_agent's` LLM (`gpt-4.1 or gpt-4o`) receives the prompt and the user's question.\n",
        "     * `It will reason:` \"To answer `'who is the mayor of NYC?'`, I need to use my `web_search` tool.\"\n",
        "     * The chunk yielded will contain an `AIMessage` that looks something like this (the exact format might vary slightly, but it often includes `tool_calls`):\n",
        "```\n",
        "============= AIMessage =============\n",
        "tool_calls=[{'name': 'web_search', 'args': {'query': 'mayor of NYC'}}]\n",
        "```\n",
        "   3. **Chunk 2: Tool Execution (Action)**\n",
        "\n",
        "     * The `create_react_agent`'s internal mechanism (which includes a ToolNode-like functionality) sees the `tool_calls` in the previous `AIMessage`.\n",
        "     * It automatically executes the `web_search` tool with the query `\"mayor of NYC\"`.\n",
        "     * The chunk yielded will contain a `ToolMessage` with the actual results from Tavily:\n",
        "```\n",
        "============= ToolMessage =============\n",
        "name: web_search\n",
        "content: Eric Adams is the 110th and current mayor of New York City, serving since January 1, 2022. He is a member of the Democratic Party... (and other relevant snippets)\n",
        "```\n",
        "\n",
        "4. **Chunk 3: research_agent's Final Response (Thought & Act)**\n",
        "\n",
        "  * The `research_agent's` LLM now receives the original user question, its own reasoning process (the `AIMessage` from step 2), and crucially, the ToolMessage with the search results.\n",
        "  * It will then synthesize this information to formulate a direct answer, following its prompt instructions (\"Respond ONLY with the results of your work...\").\n",
        "  * The chunk yielded will contain a final AIMessage like:\n",
        "\n",
        "```\n",
        "============= AIMessage =============\n",
        "Eric Adams is the current mayor of New York City, serving since January 1, 2022.\n",
        "```\n",
        "Lets break into the code:\n",
        "\n",
        "1. `for chunk in research_agent.stream(...):`\n",
        "\n",
        "  * research_agent: This is the instance of the ReAct agent you just created using `create_react_agent`.\n",
        "  * `.stream(...):` Just like with your full RAG graph, the `stream()` method on the agent allows you to run it step-by-step and receive incremental updates (chunks) as it processes the query. This is incredibly helpful for understanding the agent's reasoning and action sequence.\n",
        "  * Input `({\"messages\": [{\"role\": \"user\", \"content\": \"who is the mayor of NYC?\"}]})`:\n",
        "     * This is the initial state (a simple message list with a user query) that you're feeding to the `research_agent`.\n",
        "     * You're asking the `research_agent` directly, bypassing the `supervisor` for this test.\n",
        "2. `Inner pretty_print_messages(chunk):`\n",
        "\n",
        "  * `Assumption:` You have a helper function named `pretty_print_messages` defined somewhere else in your code. (I've included a common example implementation above for context, as it's not part of the standard LangChain library).\n",
        "  * `Purpose of pretty_print_messages:` The chunk yielded by `agent.stream()` is often a dictionary containing state updates (like new messages added by the agent). This helper function's job is to take that chunk, extract the relevant messages, and print them in a human-readable format. LangChain's `BaseMessage` objects (like `AIMessage, HumanMessage, ToolMessage`) have their own `.pretty_print()` method, which is very useful."
      ],
      "metadata": {
        "id": "VYSQMGX5bsPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import convert_to_messages\n",
        "\n",
        "\n",
        "def pretty_print_message(message, indent=False):\n",
        "    pretty_message = message.pretty_repr(html=True)\n",
        "    if not indent:\n",
        "        print(pretty_message)\n",
        "        return\n",
        "\n",
        "    indented = \"\\n\".join(\"\\t\" + c for c in pretty_message.split(\"\\n\"))\n",
        "    print(indented)\n",
        "\n",
        "\n",
        "def pretty_print_messages(update, last_message=False):\n",
        "    is_subgraph = False\n",
        "    if isinstance(update, tuple):\n",
        "        ns, update = update\n",
        "        # skip parent graph updates in the printouts\n",
        "        if len(ns) == 0:\n",
        "            return\n",
        "\n",
        "        graph_id = ns[-1].split(\":\")[0]\n",
        "        print(f\"Update from subgraph {graph_id}:\")\n",
        "        print(\"\\n\")\n",
        "        is_subgraph = True\n",
        "\n",
        "    for node_name, node_update in update.items():\n",
        "        update_label = f\"Update from node {node_name}:\"\n",
        "        if is_subgraph:\n",
        "            update_label = \"\\t\" + update_label\n",
        "\n",
        "        print(update_label)\n",
        "        print(\"\\n\")\n",
        "\n",
        "        messages = convert_to_messages(node_update[\"messages\"])\n",
        "        if last_message:\n",
        "            messages = messages[-1:]\n",
        "\n",
        "        for m in messages:\n",
        "            pretty_print_message(m, indent=is_subgraph)\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "id": "wlkHgZYtOtoh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in research_agent.stream( # 1. Execute the research_agent with streaming\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"who is the chief minister of  Karnataka?\"}]} # 2. Input query\n",
        "):\n",
        "    pretty_print_messages(chunk) # 3. Print the updates as they happen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUUakaM8IG9w",
        "outputId": "3458bc02-d1db-474f-ba5c-bb49ee07b642"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update from node agent:\n",
            "\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: research_agent\n",
            "Tool Calls:\n",
            "  tavily_search (call_qT1X9JFJhOoNxHA58OiJQ51t)\n",
            " Call ID: call_qT1X9JFJhOoNxHA58OiJQ51t\n",
            "  Args:\n",
            "    query: current chief minister of Karnataka\n",
            "\n",
            "\n",
            "Update from node tools:\n",
            "\n",
            "\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search\n",
            "\n",
            "{\"query\": \"current chief minister of Karnataka\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"List of Chief Ministers of Karnataka & Their Tenure Periods\", \"url\": \"https://www.oneindia.com/list-of-chief-ministers-of-karnataka/\", \"content\": \"Since 1947, India has seen 24 Chief Ministers in Karnataka, starting from K Chengalaraya Reddy 1947 to the current serving Chief Minister Siddaramaiah who took oath in 2023.\", \"score\": 0.9161773, \"raw_content\": null}, {\"title\": \"List Of Karnataka Ministers: Siddaramaiah Cabinet - thecurrentindia\", \"url\": \"https://www.thecurrentindia.com/govt/list-of-karnataka-ministers/\", \"content\": \"Siddaramaiah is the new chief minister of Karnataka. DK Shivakumar is the Deputy CM of the state. Rotational tenure of two-and-a-half years for both the leaders; 34 ministers in the cabinet ; Full List Of Karnataka Ministers - Siddaramaiah Cabinet Ministers. Find below the full list of 34 Karnataka ministers, their portfolios and constituencies.\", \"score\": 0.90018827, \"raw_content\": null}, {\"title\": \"Chief Minister of Karnataka - Wikipedia\", \"url\": \"https://en.wikipedia.org/wiki/Chief_Minister_of_Karnataka\", \"content\": \"The chief minister of Karnataka is the chief executive officer of the government of the Indian state of Karnataka.As per the Constitution of India, the governor of Karnataka is the state's de jure head, but de facto executive authority rests with the chief minister, a template applicable to all other Indian states. Following elections to the Karnataka Legislative Assembly, the governor usually\", \"score\": 0.68798697, \"raw_content\": null}], \"response_time\": 1.56}\n",
            "\n",
            "\n",
            "Update from node agent:\n",
            "\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: research_agent\n",
            "\n",
            "The current chief minister of Karnataka is Siddaramaiah.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "By defining `math_agent`, you're furthering your understanding of:\n",
        "\n",
        "1. `Tooling Integration`: How to expose custom Python functions as tools for an LLM agent to use.\n",
        "2. `Agent Specialization:` The power of creating highly focused `\"expert\"` agents. Instead of one large, general-purpose LLM trying to do everything, you have a team where each member excels at a specific domain `(research, math, etc.)`.\n",
        "3. `Modular AI Systems:` This approach makes your AI system more robust, easier to manage, and more scalable. If you need to improve math capabilities, you just update the `math_agent` or its tools, without affecting the `research_agent`.\n",
        "4. `Preparation for Supervisor`: Both `research_agent` and `math_agent` are now ready to be plugged into your `supervisor` agent. The `supervisor` will be the `\"traffic controller\"` that directs incoming requests to the most appropriate specialized agent.\n",
        "\n",
        "\n",
        "1.  **Defining the \"Tools\"** (add, multiply, divide)\n",
        "These three Python functions (add, multiply, divide) are crucial because they represent the specific capabilities or `\"tools\"` that your `math_agent` will possess.\n",
        "\n",
        " * `Standard Python Functions:` They are just regular Python functions that perform basic arithmetic operations. The LLM itself won't actually perform the addition or multiplication; it will call these functions to get the result.\n",
        " * `Type Hints (a: float, b: float):` These are important. They tell `LangChain` (and subsequently the LLM) what kind of input arguments these functions expect (in this case, two floating-point numbers). This helps the LLM correctly format the arguments when it decides to call a tool.\n",
        " * `Docstrings (\"\"\"Add two numbers.\"\"\"):` This is arguably the most important part for the LLM. The content of these docstrings is used by `LangChain` to describe the tool's purpose to the LLM. When the LLM is reasoning, it will see something like:\n",
        "    * `add(a: float, b: float):` \"Add two numbers.\"\n",
        "    * `multiply(a: float, b: float):` \"Multiply two numbers.\"\n",
        "    * `divide(a: float, b: float):` \"Divide two numbers.\" The LLM uses these descriptions to decide which tool is appropriate for a given task.\n",
        "\n",
        "2. **Creating the math_agent** (create_react_agent(...))\n",
        "You are again using the `create_react_agent` helper function, just like you did for the `research_agent`. This confirms you're building another ReAct (Reasoning and Acting) agent to be a specialized worker.\n",
        "\n",
        "   * `math_agent =:` You're creating an instance of this specialized agent and naming it `math_agent`.\n",
        "\n",
        "3. **Parameters of** `create_react_agent` (for the `math_agent`):\n",
        "  * `model=\"openai:gpt-4.1\":`\n",
        "\n",
        "      * This is the LLM that will serve as the \"brain\" for your `math_agent`. It will be responsible for understanding mathematical queries and deciding which of its tools (add, multiply, divide) to use.\n",
        "      * Again, ensure you're using an available model like `gpt-4o` or `gpt-4-turbo` for actual execution.\n",
        "  * `tools=[add, multiply, divide]:`\n",
        "      * This is the defining feature of your `math_agent`. This list provides the specific Python functions that the LLM powering this agent can \"call\" or \"execute.\"\n",
        "      * `LangChain` automatically takes these Python functions and converts them into a format (like a JSON schema) that the LLM can understand and generate \"tool call\" instructions for.\n",
        "  * `prompt=(...):`\n",
        "     * This is the system prompt that defines the `math_agent's` role and behavior. It's tailored specifically for math tasks.\n",
        "     * `\"You are a math agent.\\n\\n\":` Clearly establishes its identity.\n",
        "     * `\"INSTRUCTIONS:\\n- Assist ONLY with math-related tasks\\n\":` This is extremely important for a multi-agent system. It rigidly defines the math_agent's scope and limitations. It tells the agent not to try to do research, answer general knowledge questions, or any other task outside of math. This helps the supervisor agent correctly delegate tasks.\n",
        "     * `- After you're done with your tasks, respond to the supervisor directly\\n:` This instruction is consistent with the `research_agent's` prompt. It ensures all worker agents know to report their results back to the supervisor, not directly to the end-user. This maintains the supervisor's central control.\n",
        "     * `- Respond ONLY with the results of your work, do NOT include ANY other text.:` Again, this enforces clean, concise output, making it easier for the supervisor to parse and integrate the results into its overall response.\n",
        " * `name=\"math_agent\":`\n",
        "     * This assigns a unique name to this specific worker agent. This name is crucial because the `supervisor agent` will use it to decide which agent to \"wake up\" and delegate a task to when a math-related request comes in."
      ],
      "metadata": {
        "id": "Rb5RC6fegk1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Defining the \"Tools\" (Python functions) that the math_agent can use\n",
        "def add(a: float, b: float):\n",
        "    \"\"\"Add two numbers.\"\"\" # Docstring is crucial for LLM understanding\n",
        "    return a + b\n",
        "\n",
        "\n",
        "def multiply(a: float, b: float):\n",
        "    \"\"\"Multiply two numbers.\"\"\" # Docstring and type hints inform the LLM\n",
        "    return a * b\n",
        "\n",
        "\n",
        "def divide(a: float, b: float):\n",
        "    \"\"\"Divide two numbers.\"\"\"\n",
        "    return a / b\n",
        "\n",
        "# 2. Creating the math_agent using create_react_agent\n",
        "math_agent = create_react_agent(\n",
        "    model=\"openai:gpt-4.1\", # The LLM powering this specific agent\n",
        "    tools=[add, multiply, divide], # The list of tools this agent has access to\n",
        "    prompt=( # The system prompt defining the agent's role and instructions\n",
        "        \"You are a math agent.\\n\\n\"\n",
        "        \"INSTRUCTIONS:\\n\"\n",
        "        \"- Assist ONLY with math-related tasks\\n\"\n",
        "        \"- After you're done with your tasks, respond to the supervisor directly\\n\"\n",
        "        \"- Respond ONLY with the results of your work, do NOT include ANY other text.\"\n",
        "    ),\n",
        "    name=\"math_agent\",\n",
        ")"
      ],
      "metadata": {
        "id": "LTHPydphIQ-Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in math_agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"what's (3 + 5) x 7\"}]}\n",
        "):\n",
        "    pretty_print_messages(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6Wjy8wVIU1o",
        "outputId": "5f469629-8fbf-4425-89ec-0e080e265f4f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update from node agent:\n",
            "\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: math_agent\n",
            "Tool Calls:\n",
            "  add (call_fgaepN2cw0nGacEZ3EIb80lV)\n",
            " Call ID: call_fgaepN2cw0nGacEZ3EIb80lV\n",
            "  Args:\n",
            "    a: 3\n",
            "    b: 5\n",
            "\n",
            "\n",
            "Update from node tools:\n",
            "\n",
            "\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: add\n",
            "\n",
            "8.0\n",
            "\n",
            "\n",
            "Update from node agent:\n",
            "\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: math_agent\n",
            "Tool Calls:\n",
            "  multiply (call_jYxkzqTgzqeZzYE1mJtfhlyG)\n",
            " Call ID: call_jYxkzqTgzqeZzYE1mJtfhlyG\n",
            "  Args:\n",
            "    a: 8\n",
            "    b: 7\n",
            "\n",
            "\n",
            "Update from node tools:\n",
            "\n",
            "\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: multiply\n",
            "\n",
            "56.0\n",
            "\n",
            "\n",
            "Update from node agent:\n",
            "\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: math_agent\n",
            "\n",
            "56\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code represents a significant leap! You're moving from a single-agent system to a multi-agent orchestration:\n",
        "\n",
        "  **Delegation of Authority:** The supervisor becomes the central control unit. It's like a project manager assigning tasks to specialized team members.\n",
        "\n",
        "  **Modularity and Specialization:** You have distinct agents `(research_agent, math_agent)` each good at one thing. This makes the system more robust, easier to develop, and easier to scale.\n",
        "\n",
        "  **Complex Problem Solving:** By combining agents, your system can now tackle problems that require different skill sets\n",
        "  \n",
        "  **Reduced Hallucinations (Potentially):** By limiting an agent's scope (e.g., \"ONLY with research\"), it's less likely to try to generate content outside its expertise, reducing the chance of fabricating information.\n",
        "\n",
        "1. `from langgraph_supervisor import create_supervisor:`\n",
        "\n",
        "* This imports the `create_supervisor` helper function from the `langgraph-supervisor` library you installed earlier. This is a specialized utility designed to simplify the creation of supervisor agents within `LangGraph`.\n",
        "2. `from langchain_openai import ChatOpenAI:`\n",
        "\n",
        "* This imports the `ChatOpenAI` class, which is how you interact with OpenAI's chat models (like GPT-4o, GPT-4.1, etc.) through LangChain.\n",
        "3. `supervisor = create_supervisor(...):`\n",
        "* You are creating an instance of your `supervisor agent` and assigning it to the supervisor variable. This supervisor is itself a compiled `LangGraph` Runnable, meaning you can `invoke() or stream()` it just like your other agents.\n",
        "\n",
        "**Parameters of create_supervisor:**\n",
        " * `model=ChatOpenAI(model=\"gpt-4.1\"):`\n",
        "\n",
        "    * This is the Large Language Model (LLM) that powers the supervisor itself. This is the brain of the \"manager.\"\n",
        "    * This LLM's role is not to perform the tasks directly (like research or math) but to make high-level decisions:\n",
        "        * Which worker agent is best suited for the current task?\n",
        "        * Is the overall task complete?\n",
        "        * When should control be passed back to the user?\n",
        "   * Just like with your worker agents, you should use an actual available model here (e.g., gpt-4o)\n",
        "\n",
        "* `agents=[research_agent, math_agent]:`\n",
        "  * This is a list of the worker agents that this supervisor will manage.\n",
        "  * The `create_supervisor` function uses the name attribute you assigned to each worker agent `(\"research_agent\", \"math_agent\")` to understand who they are and how to refer to them.\n",
        "  * The `supervisor's` prompt will leverage these names to delegate tasks effectively.\n",
        "\n",
        "* `prompt=(...):`\n",
        "\n",
        "   * This is the system prompt specifically for the supervisor LLM. It defines its core responsibilities and constraints.\n",
        "   * `\"You are a supervisor managing two agents:\\n\":` Establishes its identity and role.\n",
        "   * `- a research agent. Assign research-related tasks to this agent\\n:` This instructs the supervisor on the capabilities of the `research_agent`. It tells the supervisor that if a task is research-related, it should delegate to this agent.\n",
        "   * `- a math agent. Assign math-related tasks to this agent\\n:` Similarly, this defines the role of the math_agent for the supervisor.\n",
        "   * `Assign work to one agent at a time, do not call agents in parallel.\\n:` This is a crucial constraint on delegation. It tells the supervisor to pick one agent and wait for its response before potentially choosing another. This sets up a sequential, single-turn delegation pattern, simplifying the orchestration.\n",
        "   * `Do not do any work yourself.:` This emphasizes that the **supervisor is purely an orchestrator.** It should never try to answer a question or perform a task directly. Its only job is to decide who should do the work.\n",
        "\n",
        "* `add_handoff_back_messages=True:`\n",
        "\n",
        "  * This is a convenience parameter for `create_supervisor`. When `True`, after a worker agent completes its task and \"hands off\" control back to the supervisor, the system automatically adds a special message to the conversation history indicating this handoff.\n",
        "  * This helps the supervisor (and you, when debugging) to clearly track the flow of control between agents within the conversation history.\n",
        "\n",
        "* `output_mode=\"full_history\":`\n",
        "\n",
        "  * This parameter dictates what the supervisor agent will return after each step of its execution.\n",
        "  * `\"full_history\":` Means that the supervisor will return the entire updated list of messages in the conversation history after each decision point or agent turn. This is very useful for debugging and understanding the full context as the conversation evolves across multiple agents. Other modes might just return the last message or a specific output.\n",
        "\n",
        "* `.compile():`\n",
        "This is the final step, identical to compiling your RAG graph. It takes all the definitions (the supervisor's model, its managed agents, its prompt, and its output rules) and builds an executable LangGraph object. The supervisor object is now ready to receive user queries and start orchestrating your worker agents."
      ],
      "metadata": {
        "id": "MM5fBO_bo4Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph_supervisor import create_supervisor\n",
        "from langchain_openai import ChatOpenAI # Corrected import for clarity (was init_chat_model)\n",
        "\n",
        "supervisor = create_supervisor(\n",
        "    model=ChatOpenAI(model=\"gpt-4.1\"), # The LLM that acts as the supervisor's brain\n",
        "    agents=[research_agent, math_agent], # The worker agents this supervisor manages\n",
        "    prompt=( # The supervisor's instructions and role definition\n",
        "        \"You are a supervisor managing two agents:\\n\"\n",
        "        \"- a research agent. Assign research-related tasks to this agent\\n\"\n",
        "        \"- a math agent. Assign math-related tasks to this agent\\n\"\n",
        "        \"Assign work to one agent at a time, do not call agents in parallel.\\n\"\n",
        "        \"Do not do any work yourself.\"\n",
        "    ),\n",
        "    add_handoff_back_messages=True, # Automatically add messages when agents hand off control\n",
        "    output_mode=\"full_history\", # The supervisor returns the full message history\n",
        ").compile() # Compile the supervisor's internal graph"
      ],
      "metadata": {
        "id": "Sa5ZmhSCmp2O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization - this is Crucial for\n",
        " * **Understanding Orchestration:** It visually clarifies how the \"manager\" LLM (the supervisor) is set up to receive a request, parse it, and then decide which specialized \"employee\" (worker agent) is best suited to handle that specific part of the task.\n",
        " * **Debugging Multi-Agent Flows:** When building complex systems, tracing the flow manually can be very difficult. A visual graph immediately shows you the intended paths and can help pinpoint unexpected loops or dead ends. If your supervisor isn't calling the right agent, this diagram is the first place to look.\n",
        " * **Architectural Clarity** It's an excellent way to document and communicate the architecture of your multi-agent system to others or to your future self!\n",
        "\n",
        " The image you'll see displayed in your notebook is a visual representation of your supervisor agent's decision-making and delegation process. It's the flowchart for your \"AI manager.\"\n",
        "\n",
        " You can expect to see:\n",
        "\n",
        "* A Central Hub (The Supervisor): There will be a prominent node representing the supervisor itself. This is where the overall orchestration logic resides.\n",
        "* Conditional Transitions to Worker Agents:\n",
        "  * You'll see arrows (edges) originating from the supervisor's node.\n",
        "  * These arrows will lead to the research_agent node and the math_agent node.\n",
        "  * These will be conditional edges, meaning the supervisor (powered by its LLM) will decide which path to take (which agent to activate) based on the input query and its internal prompt/rules. This is where you see the \"Assign research-related tasks to this agent\" and \"Assign math-related tasks to this agent\" instructions come to life.\n",
        "* Worker Agents as Nodes: The research_agent and math_agent themselves might appear as single nodes in this top-level supervisor graph, even though they also have their own internal ReAct loops (which you visualized separately). The supervisor's graph focuses on the inter-agent flow.\n",
        "* Return Paths / Handoffs: You'll see edges going back from the research_agent and math_agent nodes to the supervisor. This represents the \"After you're done with your tasks, respond to the supervisor directly\" instruction. The supervisor then re-evaluates the state after a worker has completed its part.\n",
        "* END Points: The graph will have END nodes, indicating where the supervisor determines the overall task is complete and a final response can be given.\n",
        "\n",
        "\n",
        "This code uses the IPython.display utilities (display and Image) that you used previously to visualize your single RAG agent's workflow. The core idea remains the same: to generate and display a flowchart of your agent's internal logic.\n",
        "\n",
        "1. `from IPython.display import display, Image:`\n",
        "\n",
        " * Standard imports for rendering images within an interactive Python environment (like Jupyter notebooks or Google Colab). Image lets you create an image object from data, and display renders it.\n",
        "2. `supervisor.get_graph().draw_mermaid_png():`\n",
        "\n",
        "  * `supervisor:` This refers to the compiled supervisor agent object you just created using create_supervisor(...).compile(). This object encapsulates the entire logic of how your supervisor orchestrates its worker agents.\n",
        "  * `.get_graph():` Just like with your previous graph object, this method is called on the supervisor to retrieve its underlying graph structure. create_supervisor internally builds a LangGraph StateGraph to manage the delegation and handoffs between agents. This method exposes that internal graph.\n",
        "  * `.draw_mermaid_png():` This method takes that internal graph structure, converts it into a Mermaid diagram syntax, and then renders that Mermaid diagram into a PNG image format.\n"
      ],
      "metadata": {
        "id": "JzcKVvOS7mop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image\n",
        "# Display the visual representation of the supervisor's graph\n",
        "display(Image(supervisor.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "LkUYTMmUImO-",
        "outputId": "12d236e6-0837-4b69-dbb7-2aebf8e4bdfb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code brings your AI team to life! It demonstrates:\n",
        "\n",
        " * `Dynamic Task Delegation:` How the supervisor intelligently directs tasks to the most appropriate specialized agent.\n",
        " * `Sequential Execution:` How agents work in sequence, passing control back and forth via the supervisor.\n",
        " * `Complex Problem Solving:` The ability of your system to break down a multi-faceted problem (research + calculation) and solve it using different expert components.\n",
        " * `Observability:` How stream() and pretty_print_messages provide invaluable insights into the internal workings of complex AI systems, which is crucial for debugging and optimization.\n",
        "\n",
        " 1. `for chunk in supervisor.stream(...):`\n",
        "\n",
        "  * supervisor: This is your compiled supervisor agent, the \"manager\" of your AI team.\n",
        "  * .stream(...): Just like with individual agents, you use stream() to run the supervisor. This means you'll receive updates incrementally as the supervisor makes decisions and delegates tasks to worker agents, and as those worker agents perform their work. You'll see the entire conversation unfold.\n",
        "  ```\n",
        "  {\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"find US and New York state GDP in 2024. what % of US GDP was New York state?\",\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "```\n",
        "This is the initial state passed to the supervisor. It's a deliberately complex query because it requires:\n",
        "  * Research: To find the actual GDP figures for the US and New York state in 2024.\n",
        "  * Math: To calculate the percentage of US GDP that New York state's GDP represents. This type of query is designed to trigger the supervisor's delegation logic to both your research_agent and your math_agent.\n",
        "\n",
        "2. pretty_print_messages(chunk, last_message=True):\n",
        "\n",
        " * This is your helper function.\n",
        " * `chunk:` Each chunk yielded by supervisor.stream() represents a state update from a particular node (either the supervisor itself or one of the worker agents).\n",
        " * `last_message=True:` This additional parameter (if implemented in your helper) is set to True. It tells pretty_print_messages to only display the most recent message added to the state in that specific chunk. This helps keep the output concise and focuses on what just happened, which is especially useful in complex multi-agent flows."
      ],
      "metadata": {
        "id": "_pgm5XFn_B8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in supervisor.stream( # 1. Execute the supervisor agent in streaming mode\n",
        "    {\n",
        "        \"messages\": [ # 2. The complex user query that requires delegation\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"find India and Karnataka state GDP in 2024. what % of INDIA GDP was Karnataka state?\",\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "):\n",
        "    pretty_print_messages(chunk, last_message=True) # 3. Display updates, focusing on the last message\n",
        "\n",
        "final_message_history = chunk[\"supervisor\"][\"messages\"] # 4. Capture the complete history after execution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y91O2Hd9In0W",
        "outputId": "072849bc-c960-42d0-cf28-ef7e0b8db388"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update from node supervisor:\n",
            "\n",
            "\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: transfer_to_research_agent\n",
            "\n",
            "Successfully transferred to research_agent\n",
            "\n",
            "\n",
            "Update from node research_agent:\n",
            "\n",
            "\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: transfer_back_to_supervisor\n",
            "\n",
            "Successfully transferred back to supervisor\n",
            "\n",
            "\n",
            "Update from node supervisor:\n",
            "\n",
            "\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: transfer_to_math_agent\n",
            "\n",
            "Successfully transferred to math_agent\n",
            "\n",
            "\n",
            "Update from node math_agent:\n",
            "\n",
            "\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: transfer_back_to_supervisor\n",
            "\n",
            "Successfully transferred back to supervisor\n",
            "\n",
            "\n",
            "Update from node supervisor:\n",
            "\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: supervisor\n",
            "\n",
            "India's GDP in 2024 is estimated at 324.11 trillion INR, and Karnataka's GDP is about 25 trillion INR. This means Karnataka contributed approximately 7.7% of India's total GDP in 2024.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a powerful technique for building more explicit and robust supervisor agents:\n",
        "\n",
        "**Explicit Delegation:** Instead of the supervisor's LLM just emitting a generic `tool_call` that LangGraph then magically interprets as a transition, these handoff_tools give the LLM a direct action to perform the handoff. The LLM actually says, \"I am going to transfer control to the research agent now.\"\n",
        "\n",
        "**Fine-Grained Control:** The Command object offers incredible flexibility to control graph flow (goto), update state (update), and even manage subgraphs (graph). This is essential for highly dynamic and adaptive agent systems.\n",
        "\n",
        "**Improved Observability:** Because the `handoff_tool` adds a `ToolMessage` to the state, your pretty_print_messages (or stream output) will clearly show when and to whom control was transferred, which is fantastic for debugging complex multi-agent interactions.\n",
        "\n",
        "**Foundation for Complex Orchestration:** This pattern is key for building agents that can:\n",
        "* Delegate tasks.\n",
        "* Pass context along with the delegation.\n",
        "* Receive control back.\n",
        "* Make decisions about the next step in a multi-agent workflow.\n",
        "\n",
        "We are now delving into one of the most powerful and flexible features of LangGraph: **explicitly controlling graph flow and state from within a tool!** This create_handoff_tool function is a sophisticated way to manage transitions between agents, giving the LLM more direct influence over the workflow.\n",
        "\n",
        "1. New Imports\n",
        "* `Annotated` from `typing`: This is a Python 3.9+ feature for adding metadata to type hints. It's used here to tell LangChain/LangGraph that certain function parameters should be \"injected\" automatically.\n",
        "* `tool` from `langchain_core.tools`: This is a decorator (@tool) that you place above a Python function to turn it into a tool that an LLM can understand and call.\n",
        "* `InjectedToolCallId` from `langchain_core.tools:` A special marker used with Annotated to tell LangGraph to inject the unique ID of the tool call that initiated the execution of this function. This ID is crucial for the tool to report its results back correctly.\n",
        "* `InjectedState` from `langgraph.prebuilt:` Another special marker used with Annotated to tell LangGraph to inject the current graph state into the tool function when it's called. This allows the tool to read from or modify the shared state.\n",
        "* `StateGraph, START, MessagesState from langgraph.graph:` These are core LangGraph components you're already familiar with (defining the graph, start node, and message-based state).\n",
        "* `Command from langgraph.types:` This is the most important new concept here. A Command object allows a node (or a tool within a node) to directly influence the graph's execution flow and state. It's how a tool can tell the graph things like \"go to this specific node next,\" \"update the state this way,\" or \"return to the parent graph.\"\n",
        "\n",
        "2. `def create_handoff_tool(...) (A Tool Factory)`\n",
        " * This function isn't a tool itself; it's a factory function that creates and returns a new tool function each time it's called. This allows you to generate specialized handoff tools for each agent without writing repetitive code.\n",
        "\n",
        "    * `agent_name: str:` The name of the agent to which this tool will hand off control (e.g., \"research_agent\", \"math_agent\"). This will also be used in the tool's own name and in the goto command.\n",
        "    * `description: str | None = None:` A description for the tool, which the LLM will see.\n",
        "3. The Inner `handoff_tool` Function (The Actual Tool) :\n",
        "  This is the core of the magic, defined inside create_handoff_tool. This function will become a callable tool that an LLM can use.\n",
        "  * `@tool(name, description=description):`\n",
        "    * This decorator registers `handoff_tool` as a callable tool. The name (e.g., `\"transfer_to_research_agent\"`) and description (e.g., `\"Assign task to a researcher agent.\")` are what the LLM sees in its tool-use instructions. The LLM then knows when and how to call this tool.\n",
        "  * `state: Annotated[MessagesState, InjectedState]:`\n",
        "    * When the LLM calls this `handoff_tool`, LangGraph will automatically inject the current `MessagesState` (the full conversation history and other state variables) into the state parameter of this function. This gives the tool access to the current context.\n",
        " * `tool_call_id: Annotated[str, InjectedToolCallId]:`\n",
        "    * `LangGraph` also injects the unique ID of the specific tool call that the LLM generated to invoke this `handoff_tool`. This `tool_call_id` is essential for creating a `ToolMessage` that correctly links back to the LLM's instruction.\n",
        " * `-> Command:`\n",
        "    * This type hint indicates that this tool function will return a Command object. This is how the tool explicitly tells LangGraph what to do next with the execution flow.\n",
        " * `tool_message = {...}:`\n",
        "    * This creates a dictionary representing a `ToolMessage`. This message will be added to the shared state's message history.\n",
        "    * `\"role\":` \"tool\": Marks it as a message from a tool.\n",
        "    * `\"content\":` f\"Successfully transferred to {agent_name}\": The content describes what the tool did (i.e., initiated a transfer).\n",
        "    * `\"name\":` name: The name of the tool that generated this message (e.g., \"transfer_to_research_agent\").\n",
        "    * `\"tool_call_id\":` tool_call_id: Links this ToolMessage back to the LLM's specific instruction to call this tool.\n",
        "\n",
        " * `return Command(...):` This is the core mechanism of the handoff.\n",
        "\n",
        "   * `goto=agent_name:` This is the most important part. It explicitly tells LangGraph to immediately transition the graph's execution to the node named `agent_name`. So, if `agent_name` is `\"research_agent\"`, the graph will directly jump to the `research_agent` node. This is a direct, programmatic handoff of control.\n",
        "  * `update={**state, \"messages\": state[\"messages\"] + [tool_message]}:` This tells `LangGraph` to update the shared state. It takes the existing state (**state unpacks its contents) and adds the `tool_message` (created above) to the messages list. This effectively logs the handoff in the conversation history.\n",
        "  * `graph=Command.PARENT:` This indicates that the goto command should operate within the context of the parent graph that called this tool. In your `supervisor` setup, the `supervisor's` graph is the \"parent\" of the handoff tool, and the goto command tells this parent graph to transition to a new node (e.g., research_agent).\n",
        "4. Instantiating Handoff Tools\n",
        "You are calling your `create_handoff_tool` factory function twice to create two specific handoff tools:\n",
        " * `assign_to_research_agent:` This tool, when called by an LLM, will direct the graph's flow to the `\"research_agent\"` node. Its name will be `transfer_to_research_agent`.\n",
        " * `assign_to_math_agent:` This tool, when called by an LLM, will direct the graph's flow to the `\"math_agent\"` node. Its name will be `transfer_to_math_agent`.\n"
      ],
      "metadata": {
        "id": "y-4DwJJJIEMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from langchain_core.tools import tool, InjectedToolCallId\n",
        "from langgraph.prebuilt import InjectedState\n",
        "from langgraph.graph import StateGraph, START, MessagesState\n",
        "from langgraph.types import Command\n",
        "\n",
        "\n",
        "def create_handoff_tool(*, agent_name: str, description: str | None = None):\n",
        "    name = f\"transfer_to_{agent_name}\"\n",
        "    description = description or f\"Ask {agent_name} for help.\"\n",
        "\n",
        "    @tool(name, description=description)\n",
        "    def handoff_tool(\n",
        "        state: Annotated[MessagesState, InjectedState],\n",
        "        tool_call_id: Annotated[str, InjectedToolCallId],\n",
        "    ) -> Command:\n",
        "        tool_message = {\n",
        "            \"role\": \"tool\",\n",
        "            \"content\": f\"Successfully transferred to {agent_name}\",\n",
        "            \"name\": name,\n",
        "            \"tool_call_id\": tool_call_id,\n",
        "        }\n",
        "        return Command(\n",
        "            goto=agent_name,\n",
        "            update={**state, \"messages\": state[\"messages\"] + [tool_message]},\n",
        "            graph=Command.PARENT,\n",
        "        )\n",
        "\n",
        "    return handoff_tool\n",
        "\n",
        "\n",
        "# Handoffs\n",
        "assign_to_research_agent = create_handoff_tool(\n",
        "    agent_name=\"research_agent\",\n",
        "    description=\"Assign task to a researcher agent.\",\n",
        ")\n",
        "\n",
        "assign_to_math_agent = create_handoff_tool(\n",
        "    agent_name=\"math_agent\",\n",
        "    description=\"Assign task to a math agent.\",\n",
        ")"
      ],
      "metadata": {
        "id": "BXKX-gY5IzOD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Difference and Significance for AI Engineering:\n",
        "\n",
        "The main difference between this `supervisor_agent` definition and the previous one (`create_supervisor` from `langgraph_supervisor`) is:\n",
        "\n",
        "  * **create_supervisor (pre-built):** A higher-level abstraction. You tell it which agents it manages, and it internally handles the routing logic for delegation. It's convenient for standard supervisor patterns.\n",
        "  * **create_react_agent (here):** You are building the supervisor as a standard `ReAct` agent, and its delegation capability comes from its explicit access to the `handoff_tools`.\n",
        "\n",
        "Why this approach is powerful:\n",
        "\n",
        " * **More Granular Control:** By making the supervisor a ReAct agent that explicitly calls handoff tools, you have finer control over its decision-making process. The supervisor's LLM's `\"thoughts\"` will now show it reasoning about which handoff tool to use, and then showing the `ToolMessage` indicating the handoff.\n",
        " * **Transparency:** You can more easily inspect the `supervisor's` exact thought process (its `tool_calls` for `handoff`) in the execution trace.\n",
        " * **Customization:** If you wanted to add more complex delegation logic (e.g., passing specific arguments with the handoff, adding pre-delegation checks, or even routing to a human), defining the supervisor as a ReAct agent with custom tools makes that much easier.\n",
        " * **Flexibility:** This pattern is fundamental for building highly dynamic and adaptive multi-agent systems where the routing logic might not be simple sequential calls but involves complex conditions or even human intervention as \"tools.\"\n",
        "\n",
        "1. `supervisor_agent = create_react_agent(...):`\n",
        "\n",
        " * This is the most significant change. Instead of using a specialized `create_supervisor` helper, you are now using the general-purpose `create_react_agent` to build your supervisor.\n",
        " * This means your supervisor itself will follow the **Reasoning and Acting (ReAct)** pattern. Its \"action\" will be to choose and execute one of its \"handoff\" tools.\n",
        "2. `model=\"openai:gpt-4.1\":`\n",
        " * This is the LLM that serves as the \"brain\" for this `supervisor_agent`.\n",
        " * This LLM's job is to read the incoming user message (or the output from a worker agent) and decide which tool (which of the handoff tools) it needs to call to delegate the task.\n",
        "3. `tools=[assign_to_research_agent, assign_to_math_agent]:`\n",
        "\n",
        "  * **This is the most crucial part of this definition.**\n",
        "  * Unlike the previous `create_supervisor` which implicitly understood how to delegate, this `supervisor_agent` is explicitly given the custom handoff tools you just defined **(assign_to_research_agent, assign_to_math_agent)**.\n",
        "  * When the supervisor's LLM processes an input, it will consider these `assign_to_X_agent` tools as its available actions. If it decides a task needs `research`, it will generate a tool call to `assign_to_research_agent`. If it needs math, it will call assign_to_math_agent.\n",
        "  * These `handoff` tools, as you learned, then return a Command that tells LangGraph to goto the specific worker agent's node directly.\n",
        "\n",
        "4. `prompt=(...):`\n",
        "  * This is the system prompt for this ReAct supervisor agent. It's very similar to the previous supervisor prompt, but now it's specifically guiding the ReAct agent's tool-use behavior.\n",
        "  * It tells the supervisor's LLM:\n",
        "     * `Its role:` \"You are a supervisor managing two agents.\"\n",
        "     * `How to delegate:` By instructing it to \"Assign research-related tasks to this agent\" (implying the use of assign_to_research_agent tool) and similarly for the math agent.\n",
        "     * `Constraints:` \"Assign work to one agent at a time, do not call agents in parallel.\" and \"Do not do any work yourself.\" These constraints are vital for the supervisor's LLM to make correct delegation decisions.\n",
        "\n",
        "5. `name=\"supervisor\":`\n",
        "\n",
        "This assigns the name `\"supervisor\"` to this specific `create_react_agent` instance. This name will be used when you define the overall `LangGraph` structure that includes this supervisor as a node."
      ],
      "metadata": {
        "id": "6Lzg-vrMY_PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "supervisor_agent = create_react_agent(\n",
        "    model=\"openai:gpt-4.1\", # The LLM powering the supervisor\n",
        "    tools=[assign_to_research_agent, assign_to_math_agent], # The supervisor's tools: how it delegates!\n",
        "    prompt=( # The system prompt guiding the supervisor's delegation decisions\n",
        "        \"You are a supervisor managing two agents:\\n\"\n",
        "        \"- a research agent. Assign research-related tasks to this agent\\n\"\n",
        "        \"- a math agent. Assign math-related tasks to this agent\\n\"\n",
        "        \"Assign work to one agent at a time, do not call agents in parallel.\\n\"\n",
        "        \"Do not do any work yourself.\"\n",
        "    ),\n",
        "    name=\"supervisor\", # The name of this supervisor agent\n",
        ")"
      ],
      "metadata": {
        "id": "WuqMWq2-JYMi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you run this supervisor graph (e.g., using supervisor.stream(...)):\n",
        "\n",
        "* `Start (START):` The user's query enters the graph.\n",
        "* `To Supervisor (\"supervisor\"):` The query immediately goes to your `supervisor_agent.`\n",
        "* `Supervisor's Decision`:\n",
        "  * The `supervisor_agent` (being a ReAct agent powered by its LLM) evaluates the user's query and its own prompt.\n",
        "  * Based on the query's content, it decides which `handoff_tool` to call (`assign_to_research_agent` or `assign_to_math_agent`).\n",
        "  * When it calls a `handoff_tool`, that tool's Command(goto=...) instruction directly tells the graph to jump to the respective worker agent's node.\n",
        "* `Worker Agent Executes (\"research_agent\" or \"math_agent\"):`\n",
        "  * The selected worker agent receives the delegated task.\n",
        "  * It uses its own tools (e.g., web_search or add/multiply/divide) to perform its specialized task.\n",
        "* Worker Returns to Supervisor (\"supervisor\"):\n",
        "  * Once the worker agent completes its task and formulates its response (which is intended for the `supervisor`), the fixed edge (`.add_edge(\"research_agent\", \"supervisor\")` or `.add_edge(\"math_agent\", \"supervisor\"))` immediately returns control to the supervisor node.\n",
        "* Supervisor Re-evaluates:\n",
        " * The supervisor_agent now has the original query, its own previous decisions, and the worker agent's output.\n",
        " * It re-evaluates the overall task. It might decide:\n",
        "   * To call another worker agent (e.g., research_agent completed, now call math_agent).\n",
        "   * That the task is complete, and it's time to generate a final answer to the original user query (in which case it would stop generating tool calls, and the graph would implicitly end as no further transitions are triggered).\n",
        "   * To ask for clarification."
      ],
      "metadata": {
        "id": "8zZQVsoehqK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END # Import the special END node\n",
        "\n",
        "# Define the multi-agent supervisor graph\n",
        "supervisor = (\n",
        "    StateGraph(MessagesState) # 1. Initialize the graph with a shared state\n",
        "    # 2. Add the supervisor_agent as a node in the overall graph\n",
        "    # NOTE: `destinations` is only needed for visualization and doesn't affect runtime behavior\n",
        "    .add_node(supervisor_agent, destinations=(\"research_agent\", \"math_agent\", END))\n",
        "    # 3. Add the worker agents as nodes\n",
        "    .add_node(research_agent)\n",
        "    .add_node(math_agent)\n",
        "    # 4. Define the initial entry point\n",
        "    .add_edge(START, \"supervisor\")\n",
        "    # always return back to the supervisor\n",
        "    # 5. Define the return paths from worker agents back to the supervisor\n",
        "    .add_edge(\"research_agent\", \"supervisor\")\n",
        "    .add_edge(\"math_agent\", \"supervisor\")\n",
        "    .compile() # 6. Compile the graph for execution\n",
        ")"
      ],
      "metadata": {
        "id": "IQ5xMX2qJbxP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image\n",
        "\n",
        "display(Image(supervisor.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "CRrcafXUJh_X",
        "outputId": "52d615b8-0633-4188-9684-d447842f6f4c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in supervisor.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"find India and Karnataka State GDP in 2024. what % of India GDP was Karnataka state?\",\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "):\n",
        "    pretty_print_messages(chunk, last_message=True)\n",
        "\n",
        "final_message_history = chunk[\"supervisor\"][\"messages\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2MLUBdnJnY7",
        "outputId": "ece6c4fc-5bcb-4f86-ef95-3fedbff13676"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update from node supervisor:\n",
            "\n",
            "\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: transfer_to_research_agent\n",
            "\n",
            "Successfully transferred to research_agent\n",
            "\n",
            "\n",
            "Update from node research_agent:\n",
            "\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: research_agent\n",
            "\n",
            "- India's GDP for 2024 is estimated at $3.78 trillion USD (about 324.11 lakh crore). [Source: Wikipedia](https://en.wikipedia.org/wiki/Economy_of_India)\n",
            "- Karnataka's GDP for 2024 is estimated at 25 trillion (25 lakh crore). [Source: Statista](https://www.statista.com/statistics/962125/india-gross-state-domestic-product-of-karnataka/)\n",
            "\n",
            "Karnataka's share of India's GDP in 2024 is approximately 7.7%.\n",
            "\n",
            "\n",
            "Update from node supervisor:\n",
            "\n",
            "\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: transfer_to_math_agent\n",
            "\n",
            "Successfully transferred to math_agent\n",
            "\n",
            "\n",
            "Update from node math_agent:\n",
            "\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: math_agent\n",
            "\n",
            "India's GDP in 2024: 324.11 lakh crore  \n",
            "Karnataka's GDP in 2024: 25 lakh crore  \n",
            "Karnataka's share of India's GDP: 7.71%\n",
            "\n",
            "\n",
            "Update from node supervisor:\n",
            "\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: supervisor\n",
            "\n",
            "India's GDP in 2024 is 324.11 lakh crore, and Karnataka's GDP is 25 lakh crore. Therefore, Karnataka's GDP is 7.71% of India's GDP for 2024.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Full Traceability:** This is incredibly important for understanding exactly how your multi-agent system arrived at its final answer. You can see the entire chain of thought, delegation, and tool use.\n",
        "\n",
        "**Debugging:** If your system gives an incorrect answer or gets stuck, this full message history is your primary debugging tool. You can trace back to see which agent made what decision, what information it had, and what tools it called, helping you pinpoint issues.\n",
        "\n",
        "**Observability:** It makes the complex internal workings of your AI team transparent, which is essential for building and maintaining sophisticated agentic systems."
      ],
      "metadata": {
        "id": "1tFmmZGXj6ka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for message in final_message_history:\n",
        "    message.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijb693I0JvMg",
        "outputId": "8b75a7b2-ece6-4990-9f63-c6238a1fb8f4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "find India and Karnataka State GDP in 2024. what % of India GDP was Karnataka state?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: supervisor\n",
            "Tool Calls:\n",
            "  transfer_to_research_agent (call_uMcOepg7ihnDTXOj4FmNljvc)\n",
            " Call ID: call_uMcOepg7ihnDTXOj4FmNljvc\n",
            "  Args:\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: transfer_to_research_agent\n",
            "\n",
            "Successfully transferred to research_agent\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: research_agent\n",
            "Tool Calls:\n",
            "  tavily_search (call_I8BROH2UTkiLxafOwwBFztUV)\n",
            " Call ID: call_I8BROH2UTkiLxafOwwBFztUV\n",
            "  Args:\n",
            "    query: India GDP in 2024\n",
            "    search_depth: advanced\n",
            "  tavily_search (call_v7SsxpSGc2T061t7VGKyhwKF)\n",
            " Call ID: call_v7SsxpSGc2T061t7VGKyhwKF\n",
            "  Args:\n",
            "    query: Karnataka state GDP in 2024\n",
            "    search_depth: advanced\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search\n",
            "\n",
            "{\"query\": \"India GDP in 2024\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://en.wikipedia.org/wiki/Economy_of_India\", \"title\": \"Economy of India - Wikipedia\", \"content\": \"Gross [external debt](https://en.wikipedia.org/wiki/External_debt \\\"External debt\\\")*   ![Image 53: Negative increase](https://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Increase_Negative.svg/20px-Increase_Negative.svg.png) $663.8 billion (March 2024)[[41]](https://en.wikipedia.org/wiki/Economy_of_India#cite_note-42)\\n*   (![Image 54: Positive decrease](https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/Decrease_Positive.svg/20px-Decrease_Positive.svg.png) 18.7% of GDP) [...] | 33 | [Tripura](https://en.wikipedia.org/wiki/Economy_of_Tripura \\\"Economy of Tripura\\\") | 0.31 | 3.62 | 0.10% | ![Image 601: Bhutan](https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Flag_of_Bhutan.svg/40px-Flag_of_Bhutan.svg.png)[Bhutan](https://en.wikipedia.org/wiki/Bhutan \\\"Bhutan\\\") |\\n| **Total India (202425)** | **324.11** | **3780.00** | **100%** | **India** | [...] [Current account](https://en.wikipedia.org/wiki/Current_account_(balance_of_payments) \\\"Current account (balance of payments)\\\")*   ![Image 51: Negative increase](https://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Increase_Negative.svg/20px-Increase_Negative.svg.png) $44.563 billion (2024)[[28]](https://en.wikipedia.org/wiki/Economy_of_India#cite_note-imf-go-29)[[40]](https://en.wikipedia.org/wiki/Economy_of_India#cite_note-41)\", \"score\": 0.83093774, \"raw_content\": null}], \"response_time\": 2.02}\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search\n",
            "\n",
            "{\"query\": \"Karnataka state GDP in 2024\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.statista.com/statistics/962125/india-gross-state-domestic-product-of-karnataka/\", \"title\": \"State GDP of Karnataka in India FY 2011-2024 - Statista\", \"content\": \"[](https://www.statista.com/statistics/962125/india-gross-state-domestic-product-of-karnataka/#statisticContainer)\\nIn the financial year of 2024, the gross domestic product of the southern state of Karnataka amounted to about 25 trillion Indian rupees, up from about 23 trillion Indian rupees in the previous year. There was a gradual increase in the value over the years across this state.\\n\\n Read more \\n\\n Advertisement \\n\\n Advertisement [...] .com/statistics/962125/india-gross-state-domestic-product-of-karnataka/)[](mailto:?subject=Statista%C2%A0-%C2%A0Gross%20state%20domestic%20product%20at%20factor%20cost%20of%20Karnataka%20in%20India%20from%20financial%20year%202012%20to%202024%20(in%20trillion%20Indian%20rupees)&body=In%20the%20financial%20year%20of%202024,%20the%20gross%20domestic%20product%20of%20the%20southern%20state%20of%20Karnataka%20amounted%20to%20about%2025%20trillion%20Indian%20rupees\", \"score\": 0.95282507, \"raw_content\": null}, {\"url\": \"https://www.thehindu.com/business/karnatakas-economy-outpaces-national-growth-despite-global-headwinds/article68778095.ece\", \"title\": \"Karnataka's economy outpaces national growth despite global ...\", \"content\": \"Karnataka has registered GSDP growth of 10.2% in FY 2023-24, surpassing the national average of 8.2% Karnataka has registered a robust Gross State Domestic Product (GSDP) growth of 10.2% in FY 2023-24, significantly surpassing the national average of 8.2%, according to data from the Ministry of Statistics and Programme Implementation (MoSPI). Initially, the National Statistical Estimate (NSE) had projected a modest 4% GSDP growth for Karnataka, but this was revised to 13.1% by the end of the fiscal year, indicating early underestimation of the States economic performance. Karnataka continued to drive economic progress in India, registering a robust Gross State Domestic Product (GSDP) growth of 10.2% in FY 2023-24, significantly surpassing the national average of 8.2%, according to data from the Ministry of Statistics and Programme Implementation (MoSPI).\", \"score\": 0.9257218, \"raw_content\": null}, {\"url\": \"https://www.linkedin.com/pulse/gdp-indian-states-2024-rankings-growth-analysis-business-apac-fw24f\", \"title\": \"GDP of Indian States: 2024 Rankings & Growth Analysis - LinkedIn\", \"content\": \"The states pharmaceutical industry is also growing fast, thanks to dedicated industrial parks and pro-business policies. This creates more opportunities for jobs and economic growth.\\n\\n### 3. Karnataka\\n\\n*   Key Industries: IT, Aerospace and Defense, and Biotech\\n\\nKarnatakas economy is booming, making it a leader in the GDP of Indian States. The GSDP for 2024-25 is expected to reach 28.09 lakh crore (US$340 billion), with a 17.7% growth rate.\", \"score\": 0.9237645, \"raw_content\": null}], \"response_time\": 1.75}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: research_agent\n",
            "\n",
            "- India's GDP for 2024 is estimated at $3.78 trillion USD (about 324.11 lakh crore). [Source: Wikipedia](https://en.wikipedia.org/wiki/Economy_of_India)\n",
            "- Karnataka's GDP for 2024 is estimated at 25 trillion (25 lakh crore). [Source: Statista](https://www.statista.com/statistics/962125/india-gross-state-domestic-product-of-karnataka/)\n",
            "\n",
            "Karnataka's share of India's GDP in 2024 is approximately 7.7%.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: supervisor\n",
            "Tool Calls:\n",
            "  transfer_to_math_agent (call_UZlWLzhyOvHkRY0Rn0E653rh)\n",
            " Call ID: call_UZlWLzhyOvHkRY0Rn0E653rh\n",
            "  Args:\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: transfer_to_math_agent\n",
            "\n",
            "Successfully transferred to math_agent\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: math_agent\n",
            "Tool Calls:\n",
            "  divide (call_C1NLZOMLu9M9rmshVVfkq7u0)\n",
            " Call ID: call_C1NLZOMLu9M9rmshVVfkq7u0\n",
            "  Args:\n",
            "    a: 25\n",
            "    b: 324.11\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: divide\n",
            "\n",
            "0.07713430625404954\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: math_agent\n",
            "\n",
            "India's GDP in 2024: 324.11 lakh crore  \n",
            "Karnataka's GDP in 2024: 25 lakh crore  \n",
            "Karnataka's share of India's GDP: 7.71%\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: supervisor\n",
            "\n",
            "India's GDP in 2024 is 324.11 lakh crore, and Karnataka's GDP is 25 lakh crore. Therefore, Karnataka's GDP is 7.71% of India's GDP for 2024.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall Significance :\n",
        "This Send command and the `task_description` in the handoff tool are huge improvements for building robust multi-agent systems:\n",
        "\n",
        " * `Precise Delegation:` Instead of hoping a worker agent understands its task from a long, complex message history, the supervisor can now give it a direct, focused instruction.\n",
        " * `Context Isolation:` By creating agent_input with only the task_description_message (and potentially the full historical state for context), you can give the worker agents a clean, isolated view of their current sub-task. This prevents them from getting confused by irrelevant parts of the conversation.\n",
        " * `Reduced Ambiguity:` This explicit communication minimizes misunderstandings between agents, leading to more reliable task execution.\n",
        " * `Improved Debugging:` The task_description messages in your history will clearly show what instructions the supervisor gave to each worker, making the flow even more transparent.\n",
        " * `Robustness:` This pattern helps in building more resilient agents that can better handle complex multi-step problems by ensuring clear communication and task boundaries between specialized components.\n",
        "\n",
        "  This new code introduces a way for your supervisor agent to not just delegate a task to a worker agent, but to also provide a specific, explicit task description or instruction along with that delegation. This makes the communication between agents much clearer and more robust.\n",
        "\n",
        "1. New Import\n",
        "```\n",
        "from langgraph.types import Send\n",
        "```\n",
        "* `Send:` This is a crucial new `LangGraph` type. When you return a Command(goto=[Send(...)]) from a node (or a tool within a node), you are telling LangGraph to not just go to a target node, but to also send a specific input payload to that target node. This is the mechanism that allows the `task_description` to be passed explicitly.\n",
        "\n",
        "2. ` def create_task_description_handoff_tool(...) (Enhanced Handoff Tool Factory) `\n",
        " * This is a more sophisticated version of your previous create_handoff_tool. Its purpose is to create a handoff tool that takes an explicit task_description as an argument from the calling LLM.\n",
        "   * name = f\"transfer_to_{agent_name}\" and description = description or f\"Ask {agent_name} for help.\":\n",
        "     * These are the same as before. They define the name and description that the supervisor LLM will see when deciding to use this tool.\n",
        "  * `@tool(name, description=description):`\n",
        "    * Again, this decorator turns the inner `handoff_tool` function into a callable tool for an LLM.\n",
        "\n",
        "  * `def handoff_tool(...):` This is the actual tool function that will be created and exposed.\n",
        "    * `task_description: Annotated[str, \"Description of what the next agent should do, including all of the relevant context.\"]:`\n",
        "      * This is the key addition. This parameter tells LangGraph that when the supervisor LLM decides to call this handoff_tool, the LLM is expected to provide a string value for task_description.\n",
        "      * The string `\"Description of what the next agent should do...\"` serves as a docstring/description for the LLM, guiding it on what kind of string to generate for this argument.\n",
        "      * This means the supervisor LLM will effectively say: `\"Call transfer_to_research_agent with task_description='Please find the current GDP figures for X and Y.'\"`\n",
        "    * `state: Annotated[MessagesState, InjectedState],:`\n",
        "       * Similar to before, the full current state of the graph is still InjectedState into the tool.\n",
        "       * The comment # these parameters are ignored by the LLM is important: it means the LLM isn't expected to generate a value for state when calling the tool; LangGraph injects it automatically.\n",
        "    * `-> Command:`\n",
        "       * The tool still returns a Command object to control the graph's flow.\n",
        "    * `task_description_message = {\"role\": \"user\", \"content\": task_description}:`\n",
        "      * This creates a new message dictionary. Notice its role is \"user\" and its content is the `task_description` that the supervisor LLM just provided. This new message essentially simulates the supervisor \"asking\" the worker agent a direct question or giving it a specific instruction.\n",
        "    * `agent_input = {**state, \"messages\": [task_description_message]}:`\n",
        "\n",
        "      * This is the specific input payload that will be sent to the target worker agent.\n",
        "      * It takes the **state (the entire current graph state, including all previous messages).\n",
        "      * Crucially, it then replaces or overwrites the messages part of that state with a new list containing only the task_description_message. This means the worker agent primarily receives its task as a concise, direct instruction, rather than having to parse it out of the entire, potentially long, conversation history. This isolates the worker agent to its immediate sub-task.\n",
        "    \n",
        "   * `return Command(goto=[Send(agent_name, agent_input)], graph=Command.PARENT):`\n",
        "    * `goto=[Send(agent_name, agent_input)]:` This is the core of the enhanced handoff.\n",
        "    * Instead of goto=agent_name (which just transfers control), goto=[Send(target_node_name, input_payload)] explicitly instructs LangGraph to:\n",
        "      1. Move execution to the node named agent_name.\n",
        "      2. Pass the agent_input dictionary as the specific input to that agent_name node's LLM.\n",
        "  * `graph=Command.PARENT:` Still indicates that the command operates within the context of the calling (supervisor's) graph.\n",
        "\n",
        "  3. Instantiating Enhanced Handoff Tools\n",
        "  ```\n",
        "  assign_to_research_agent_with_description = create_task_description_handoff_tool(...)\n",
        "assign_to_math_agent_with_description = create_task_description_handoff_tool(...)\n",
        "```\n",
        "  * These lines create specific instances of the new handoff_tool for your research_agent and math_agent. Now, when the supervisor calls these tools, it must provide a task_description.\n",
        "\n",
        "  4. `supervisor_agent_with_description = create_react_agent(...)`\n",
        "     * This creates your new supervisor agent.\n",
        "     * `tools=[assign_to_research_agent_with_description, assign_to_math_agent_with_description]:`\n",
        "       * This is the key. The supervisor's LLM is now given access to these new handoff tools. When the supervisor decides to delegate, it won't just call a tool; it will call a tool and pass it a specific task_description string.\n",
        "     * prompt: The prompt remains similar, but the supervisor LLM's internal reasoning (due to the available tools) will lead it to generate clear task descriptions for its worker agents.\n",
        "\n",
        "  5. `. supervisor_with_description = StateGraph(...)` (Overall Graph Definition)\n",
        "    * This defines the overall graph structure, largely similar to your previous graph.\n",
        "    * `.add_node(supervisor_agent_with_description, destinations=(\"research_agent\", \"math_agent\")):`\n",
        "      * The graph now uses the new supervisor_agent_with_description as its central orchestrator.\n",
        "      * (Note: END is removed from destinations in this snippet compared to your previous one, which is a minor detail and doesn't change the core Send functionality. The graph will still end when the supervisor stops generating tool calls).\n",
        "    * The edges remain the same: START to supervisor, and worker agents always returning to supervisor"
      ],
      "metadata": {
        "id": "SfsJxMzNtZ4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.types import Send\n",
        "\n",
        "\n",
        "def create_task_description_handoff_tool(\n",
        "    *, agent_name: str, description: str | None = None\n",
        "):\n",
        "    name = f\"transfer_to_{agent_name}\"\n",
        "    description = description or f\"Ask {agent_name} for help.\"\n",
        "\n",
        "    @tool(name, description=description)\n",
        "    def handoff_tool(\n",
        "        # this is populated by the supervisor LLM\n",
        "        task_description: Annotated[\n",
        "            str,\n",
        "            \"Description of what the next agent should do, including all of the relevant context.\",\n",
        "        ],\n",
        "        # these parameters are ignored by the LLM\n",
        "        state: Annotated[MessagesState, InjectedState],\n",
        "    ) -> Command:\n",
        "        task_description_message = {\"role\": \"user\", \"content\": task_description}\n",
        "        agent_input = {**state, \"messages\": [task_description_message]}\n",
        "        return Command(\n",
        "            goto=[Send(agent_name, agent_input)],\n",
        "            graph=Command.PARENT,\n",
        "        )\n",
        "\n",
        "    return handoff_tool\n",
        "\n",
        "\n",
        "assign_to_research_agent_with_description = create_task_description_handoff_tool(\n",
        "    agent_name=\"research_agent\",\n",
        "    description=\"Assign task to a researcher agent.\",\n",
        ")\n",
        "\n",
        "assign_to_math_agent_with_description = create_task_description_handoff_tool(\n",
        "    agent_name=\"math_agent\",\n",
        "    description=\"Assign task to a math agent.\",\n",
        ")\n",
        "\n",
        "supervisor_agent_with_description = create_react_agent(\n",
        "    model=\"openai:gpt-4.1\",\n",
        "    tools=[\n",
        "        assign_to_research_agent_with_description,\n",
        "        assign_to_math_agent_with_description,\n",
        "    ],\n",
        "    prompt=(\n",
        "        \"You are a supervisor managing two agents:\\n\"\n",
        "        \"- a research agent. Assign research-related tasks to this assistant\\n\"\n",
        "        \"- a math agent. Assign math-related tasks to this assistant\\n\"\n",
        "        \"Assign work to one agent at a time, do not call agents in parallel.\\n\"\n",
        "        \"Do not do any work yourself.\"\n",
        "    ),\n",
        "    name=\"supervisor\",\n",
        ")\n",
        "\n",
        "supervisor_with_description = (\n",
        "    StateGraph(MessagesState)\n",
        "    .add_node(\n",
        "        supervisor_agent_with_description, destinations=(\"research_agent\", \"math_agent\")\n",
        "    )\n",
        "    .add_node(research_agent)\n",
        "    .add_node(math_agent)\n",
        "    .add_edge(START, \"supervisor\")\n",
        "    .add_edge(\"research_agent\", \"supervisor\")\n",
        "    .add_edge(\"math_agent\", \"supervisor\")\n",
        "    .compile()\n",
        ")"
      ],
      "metadata": {
        "id": "2FdSGGBPJ6ZY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in supervisor.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"find INDIA and Karnataka state GDP in 2024. what % of INDIA GDP was Karnataka state?\",\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    subgraphs=True,\n",
        "):\n",
        "    pretty_print_messages(chunk, last_message=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sq14jjBJ_Cu",
        "outputId": "0283ed10-3723-40a3-8d77-8cfca455eb9d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update from subgraph supervisor:\n",
            "\n",
            "\n",
            "\tUpdate from node agent:\n",
            "\n",
            "\n",
            "\t==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\tName: supervisor\n",
            "\tTool Calls:\n",
            "\t  transfer_to_research_agent (call_CsaresMBUWcIUQZVx98zWRvU)\n",
            "\t Call ID: call_CsaresMBUWcIUQZVx98zWRvU\n",
            "\t  Args:\n",
            "\n",
            "\n",
            "Update from subgraph research_agent:\n",
            "\n",
            "\n",
            "\tUpdate from node agent:\n",
            "\n",
            "\n",
            "\t==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\tName: research_agent\n",
            "\tTool Calls:\n",
            "\t  tavily_search (call_nk3NWmQzquyKS6lhkAG09fms)\n",
            "\t Call ID: call_nk3NWmQzquyKS6lhkAG09fms\n",
            "\t  Args:\n",
            "\t    query: India GDP 2024\n",
            "\t    search_depth: advanced\n",
            "\t  tavily_search (call_qpmq1GQYgMX8DkxfhPu79emL)\n",
            "\t Call ID: call_qpmq1GQYgMX8DkxfhPu79emL\n",
            "\t  Args:\n",
            "\t    query: Karnataka state GDP 2024\n",
            "\t    search_depth: advanced\n",
            "\n",
            "\n",
            "Update from subgraph research_agent:\n",
            "\n",
            "\n",
            "\tUpdate from node tools:\n",
            "\n",
            "\n",
            "\t=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\tName: tavily_search\n",
            "\t\n",
            "\t{\"query\": \"India GDP 2024\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://en.wikipedia.org/wiki/Economy_of_India\", \"title\": \"Economy of India - Wikipedia\", \"content\": \"Gross [external debt](https://en.wikipedia.org/wiki/External_debt \\\"External debt\\\")*   ![Image 53: Negative increase](https://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Increase_Negative.svg/20px-Increase_Negative.svg.png) $663.8 billion (March 2024)[[41]](https://en.wikipedia.org/wiki/Economy_of_India#cite_note-42)\\n*   (![Image 54: Positive decrease](https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/Decrease_Positive.svg/20px-Decrease_Positive.svg.png) 18.7% of GDP) [...] | 33 | [Tripura](https://en.wikipedia.org/wiki/Economy_of_Tripura \\\"Economy of Tripura\\\") | 0.31 | 3.62 | 0.10% | ![Image 601: Bhutan](https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Flag_of_Bhutan.svg/40px-Flag_of_Bhutan.svg.png)[Bhutan](https://en.wikipedia.org/wiki/Bhutan \\\"Bhutan\\\") |\\n| **Total India (202425)** | **324.11** | **3780.00** | **100%** | **India** | [...] [Current account](https://en.wikipedia.org/wiki/Current_account_(balance_of_payments) \\\"Current account (balance of payments)\\\")*   ![Image 51: Negative increase](https://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Increase_Negative.svg/20px-Increase_Negative.svg.png) $44.563 billion (2024)[[28]](https://en.wikipedia.org/wiki/Economy_of_India#cite_note-imf-go-29)[[40]](https://en.wikipedia.org/wiki/Economy_of_India#cite_note-41)\", \"score\": 0.8396422, \"raw_content\": null}], \"response_time\": 2.34}\n",
            "\n",
            "\n",
            "Update from subgraph research_agent:\n",
            "\n",
            "\n",
            "\tUpdate from node tools:\n",
            "\n",
            "\n",
            "\t=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\tName: tavily_search\n",
            "\t\n",
            "\t{\"query\": \"Karnataka state GDP 2024\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.statista.com/statistics/962125/india-gross-state-domestic-product-of-karnataka/\", \"title\": \"State GDP of Karnataka in India FY 2011-2024 - Statista\", \"content\": \"[](https://www.statista.com/statistics/962125/india-gross-state-domestic-product-of-karnataka/#statisticContainer)\\nIn the financial year of 2024, the gross domestic product of the southern state of Karnataka amounted to about 25 trillion Indian rupees, up from about 23 trillion Indian rupees in the previous year. There was a gradual increase in the value over the years across this state.\\n\\n Read more \\n\\n Advertisement \\n\\n Advertisement [...] .com/statistics/962125/india-gross-state-domestic-product-of-karnataka/)[](mailto:?subject=Statista%C2%A0-%C2%A0Gross%20state%20domestic%20product%20at%20factor%20cost%20of%20Karnataka%20in%20India%20from%20financial%20year%202012%20to%202024%20(in%20trillion%20Indian%20rupees)&body=In%20the%20financial%20year%20of%202024,%20the%20gross%20domestic%20product%20of%20the%20southern%20state%20of%20Karnataka%20amounted%20to%20about%2025%20trillion%20Indian%20rupees [...] ,%20up%20from%20about%2023%20trillion%20Indian%20rupees%20in%20the%20previous%20year\", \"score\": 0.94956195, \"raw_content\": null}, {\"url\": \"https://www.statista.com/statistics/915749/india-net-state-domestic-product-of-karnataka-at-current-prices/\", \"title\": \"India: net state domestic product of Karnataka at current prices 2024\", \"content\": \"In financial year 2024, the net state domestic product of Karnataka in India amounted to about 23 trillion Indian rupees. This was around 21 trillion rupees in the previous financial year, indicating a good growth curve for the state. Overall, Karnataka was known to be one of the states with the highest economic growth.\\n\\n## Net state domestic product of Karnataka in India at current prices from financial year 2012 to 2024 (in billion Indian rupees)\", \"score\": 0.9281033, \"raw_content\": null}, {\"url\": \"https://www.thehindu.com/business/karnatakas-economy-outpaces-national-growth-despite-global-headwinds/article68778095.ece\", \"title\": \"Karnataka's economy outpaces national growth despite global ...\", \"content\": \"Karnataka has registered GSDP growth of 10.2% in FY 2023-24, surpassing the national average of 8.2% Karnataka has registered a robust Gross State Domestic Product (GSDP) growth of 10.2% in FY 2023-24, significantly surpassing the national average of 8.2%, according to data from the Ministry of Statistics and Programme Implementation (MoSPI). Initially, the National Statistical Estimate (NSE) had projected a modest 4% GSDP growth for Karnataka, but this was revised to 13.1% by the end of the fiscal year, indicating early underestimation of the States economic performance. Karnataka continued to drive economic progress in India, registering a robust Gross State Domestic Product (GSDP) growth of 10.2% in FY 2023-24, significantly surpassing the national average of 8.2%, according to data from the Ministry of Statistics and Programme Implementation (MoSPI).\", \"score\": 0.91901255, \"raw_content\": null}], \"response_time\": 3.91}\n",
            "\n",
            "\n",
            "Update from subgraph research_agent:\n",
            "\n",
            "\n",
            "\tUpdate from node agent:\n",
            "\n",
            "\n",
            "\t==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\tName: research_agent\n",
            "\t\n",
            "\t- India's GDP in 2024 is approximately $3.78 trillion USD (about 324.11 trillion Indian rupees). [Source: Wikipedia]\n",
            "\t- Karnataka's GDP in 2024 is about 25 trillion Indian rupees. [Source: Statista]\n",
            "\t\n",
            "\tKarnataka's share of India's GDP in 2024 is roughly 7.7%.\n",
            "\n",
            "\n",
            "Update from subgraph supervisor:\n",
            "\n",
            "\n",
            "\tUpdate from node agent:\n",
            "\n",
            "\n",
            "\t==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\tName: supervisor\n",
            "\tTool Calls:\n",
            "\t  transfer_to_math_agent (call_byTGJz76FULgyztxDLVpMx8O)\n",
            "\t Call ID: call_byTGJz76FULgyztxDLVpMx8O\n",
            "\t  Args:\n",
            "\n",
            "\n",
            "Update from subgraph math_agent:\n",
            "\n",
            "\n",
            "\tUpdate from node agent:\n",
            "\n",
            "\n",
            "\t==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\tName: math_agent\n",
            "\tTool Calls:\n",
            "\t  divide (call_ScZVnItgSUYHaxiIvNhDWhS8)\n",
            "\t Call ID: call_ScZVnItgSUYHaxiIvNhDWhS8\n",
            "\t  Args:\n",
            "\t    a: 25\n",
            "\t    b: 324.11\n",
            "\n",
            "\n",
            "Update from subgraph math_agent:\n",
            "\n",
            "\n",
            "\tUpdate from node tools:\n",
            "\n",
            "\n",
            "\t=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\tName: divide\n",
            "\t\n",
            "\t0.07713430625404954\n",
            "\n",
            "\n",
            "Update from subgraph math_agent:\n",
            "\n",
            "\n",
            "\tUpdate from node agent:\n",
            "\n",
            "\n",
            "\t==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\tName: math_agent\n",
            "\tTool Calls:\n",
            "\t  multiply (call_ePzEF0Tl7bHoAgXhSt6N3yg9)\n",
            "\t Call ID: call_ePzEF0Tl7bHoAgXhSt6N3yg9\n",
            "\t  Args:\n",
            "\t    a: 0.07713430625404954\n",
            "\t    b: 100\n",
            "\n",
            "\n",
            "Update from subgraph math_agent:\n",
            "\n",
            "\n",
            "\tUpdate from node tools:\n",
            "\n",
            "\n",
            "\t=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\tName: multiply\n",
            "\t\n",
            "\t7.713430625404954\n",
            "\n",
            "\n",
            "Update from subgraph math_agent:\n",
            "\n",
            "\n",
            "\tUpdate from node agent:\n",
            "\n",
            "\n",
            "\t==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\tName: math_agent\n",
            "\t\n",
            "\tKarnataka's share of India's GDP in 2024 is approximately 7.71%.\n",
            "\n",
            "\n",
            "Update from subgraph supervisor:\n",
            "\n",
            "\n",
            "\tUpdate from node agent:\n",
            "\n",
            "\n",
            "\t==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\tName: supervisor\n",
            "\t\n",
            "\t- India's GDP in 2024: 324.11 trillion Indian rupees\n",
            "\t- Karnataka's GDP in 2024: 25 trillion Indian rupees\n",
            "\t\n",
            "\tKarnataka accounted for approximately 7.71% of India's GDP in 2024.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions & Clarifications\n",
        "\n",
        "a. How langchain-openai package is different from langchain[openai]\n",
        "  * langchain[openai]:\n",
        "\n",
        "      * This is the older way of installing OpenAI integrations within LangChain.\n",
        "      * When you install langchain[openai], it means you are installing the core langchain library, and simultaneously, pip will install the necessary dependencies for OpenAI integrations alongside the core LangChain package. These dependencies were often \"bundled\" with langchain itself, but only activated if you specified the [openai] extra.\n",
        "      * This approach meant that the core langchain package became quite large over time, as it had to manage many optional dependencies for different providers.\n",
        "      * langchain (the base package): This is the core LangChain library. It provides the fundamental abstractions, classes, and tools (like BaseChatModel, PromptTemplate, Runnable, AgentExecutor, etc.) that are common across all LLM providers and integrations. It defines what an LLM or a chat model is, but it doesn't contain the specific code to connect to any particular LLM provider (like OpenAI, Anthropic, Google, etc.).\n",
        "      * It tells pip: \"Install the base langchain package, AND also install all the additional dependencies that are needed for the openai integration.\"\n",
        "      * What it does internally: When you use langchain[openai], pip will automatically install the langchain-openai package (and any other underlying dependencies required for it) for you. It's a convenience mechanism.\n",
        "      * When you use it: This was a more common way to install specific integrations in older versions of LangChain or when you wanted a quick way to get the core langchain with a specific integration without explicitly installing the separate partner package. While it still works, the more modern approach often encourages explicit installation of langchain-openai if that's what you need.\n",
        "\n",
        "  * langchain-openai:\n",
        "\n",
        "     * langchain-openai is a separate, dedicated package (often called an \"integrations package\" or \"partner package\"). It lives independently of the core langchain library.\n",
        "\n",
        "     * It contains only the code and dependencies specifically required for interacting with OpenAI's models (like ChatOpenAI, OpenAIEmbeddings, etc.).\n",
        "     * Its sole purpose is to provide the specific integration code for OpenAI's models within the LangChain framework. This includes classes like ChatOpenAI, OpenAIEmbeddings, OpenAI, and AzureOpenAI.\n",
        "     * Why it exists: LangChain's architecture has moved towards a \"partner package\" model. Instead of having all integrations bundled into one massive langchain package, they are now separated into smaller, dedicated packages like langchain-openai, langchain-google-genai, langchain-community, etc. This makes the core langchain package lighter, reduces unnecessary dependencies, and allows partner packages to be developed and released more independently.\n",
        "     * When you use it: You explicitly pip install langchain-openai when you know you'll be working with OpenAI models. Then you'd import directly from it, e.g., from langchain_openai import ChatOpenAI.\n",
        "     * Why this change? LangChain moved to a modular approach to:\n",
        "\n",
        "       * Reduce langchain's footprint: The core langchain package becomes much lighter.\n",
        "       * Improve dependency management: You only install what you need, avoiding conflicts or unnecessary packages.\n",
        "       * Faster development/releases: Integrations can be updated and released independently of the core library.\n",
        "       * Clearer separation of concerns: The core framework is separate from specific provider integrations.\n",
        "\n",
        "   * In your code: When you see from langchain_openai import ChatOpenAI, you are directly importing from this dedicated langchain-openai package. This is the modern practice.\n",
        "\n",
        "   In essence: langchain[openai] was a way to get OpenAI dependencies with the monolithic langchain package. langchain-openai is a distinct, smaller, and focused package dedicated only to OpenAI integrations, requiring a separate pip install. In summary:\n",
        "  \n",
        "     * langchain-openai: The actual Python package containing the OpenAI integration code.\n",
        "     * langchain[openai]: A convenience syntax for pip install that ensures the langchain-openai package (and its dependencies) are installed alongside the core langchain package.\n",
        "\n",
        "\n",
        "b. How tanvily search is different from duckduckgosearch\n",
        "\n",
        "Both Tavily Search and DuckDuckGo Search provide web search capabilities that can be integrated into AI agents, but they differ significantly in their design, purpose, and features for this use case.\n",
        "\n",
        "1. `DuckDuckGo Search (via LangChain's DuckDuckGoSearchRun or similar):`\n",
        "\n",
        "   * Nature: It's an integration with the standard DuckDuckGo search engine.\n",
        "   * Primary Goal: DuckDuckGo's main focus is privacy. It aims to provide search results without tracking your personal information or search history.\n",
        "  * For AI Agents:\n",
        "     * Free: Generally free to use (though there might be rate limits if you hammer it too hard).\n",
        "     * Standard Web Search Results: It returns standard search result snippets (title, URL, brief description) similar to what you'd see in a browser.\n",
        "     * Less Optimized for LLMs: While usable, the raw search results might require more post-processing by your LLM to extract the most relevant information for an answer. It's not specifically designed to filter or summarize content for an LLM's consumption.\n",
        "     * Rate Limits: Being a public search engine, it might have more aggressive rate limits for programmatic access compared to APIs designed for agents.\n",
        "\n",
        "2. `Tavily Search (via langchain-tavily):`\n",
        "\n",
        "   * `Nature:` It's a search API specifically optimized for AI agents and LLMs. It's not just a wrapper around a general-purpose search engine.\n",
        "   * `Primary Goal:` To provide highly relevant, concise, and structured search results that are directly usable by LLMs for tasks like RAG, fact-checking, and agentic reasoning. It aims to reduce hallucination and provide accurate context.\n",
        "   * For AI Agents:\n",
        "     * Purpose-Built for LLMs/RAG: This is its biggest differentiator. Tavily focuses on searching, scraping, filtering, and extracting the most relevant information from online sources in a single API call. It often provides content snippets or even AI-generated summaries specifically tailored for RAG.\n",
        "     * Paid Service (with Free Tiers/Credits): While it's a commercial product, it typically offers generous free credits or low-cost tiers for development and initial usage.\n",
        "     * Structured Output: Results are often more structured and easier for an LLM to parse and use as context, potentially including cleaned content from web pages, not just snippets.\n",
        "     * Customization: Offers features like customizable search depths, domain management (include/exclude specific websites), and control over HTML parsing.\n",
        "     * Performance: Designed for speed and efficiency for programmatic access.\n",
        "     * Reduced LLM Load: By providing more pre-processed and relevant content, it can potentially reduce the amount of reasoning and parsing your LLM needs to do, which can save tokens and improve answer quality.\n",
        "\n",
        "    In summary:\n",
        "\n",
        "      `DuckDuckGo Search`: Good for basic, free, privacy-focused web search when you need general results and your LLM can handle more post-processing.\n",
        "\n",
        "     `Tavily Search`: Preferred for AI agents when you need highly optimized, pre-processed, and relevant search results specifically for LLM consumption, aiming to improve RAG accuracy and reduce hallucination, even if it comes with a cost (or free tier).\n",
        "\n",
        "c. Is it possible to get to the source code of TavilySearch ?\n",
        "   * Search on GitHub: The most straightforward way is to go to GitHub.com and search for \"langchain-tavily\" or \"tavily-ai/langchain-tavily\".\n",
        "   * Check the Documentation: LangChain's official documentation for TavilySearch (e.g., python.langchain.com/docs/integrations/tools/tavily_search/) will almost always have a link to the relevant GitHub repository.\n",
        "   * Check PyPI: If you go to the PyPI page for langchain-tavily (search \"langchain-tavily pypi\"), you'll usually find a \"Homepage\" or \"Source Code\" link that points to the GitHub repository.\n",
        "   * GitHub Repository: https://github.com/tavily-ai/langchain-tavily\n",
        "   * tavily-python. You can find that here: https://github.com/tavily-ai/tavily-python"
      ],
      "metadata": {
        "id": "hHT4m-gKIzGg"
      }
    }
  ]
}